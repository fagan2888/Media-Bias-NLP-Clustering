{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of this document is to take these two files and save them in a way that Github can store them\n",
    "\n",
    "1.25 GB = google_news_dictionary_article_text.pickle\n",
    "673.4MB = google_news_texts_only.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "from bson import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "google_news_dictionary_article_text = pickle.load( open( \"../Resources/Pickles/google_news_dictionary_article_text.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_item = google_news_dictionary_article_text[\"http://www.philly.com/philly/columnists/20150426_Forget_his_stats__Tim_Tebow_is_a_great_leader.html\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163184"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(google_news_dictionary_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# \"_id\" is apparently stored as a format which can't be serialized... converting it to string via this encoder \n",
    "# encoder courtesy of: http://stackoverflow.com/questions/16586180/typeerror-objectid-is-not-json-serializable\n",
    "\n",
    "class JSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, ObjectId):\n",
    "            return str(o)\n",
    "        return json.JSONEncoder.default(self, o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000 24000 25000 26000 27000 28000 29000 30000 31000 32000 33000 34000 35000 36000 37000 38000 39000 40000 41000 42000 43000 44000 45000 46000 47000 48000 49000 50000 51000 52000 53000 54000 55000 56000 57000 58000 59000 60000 61000 62000 63000 64000 65000 66000 67000 68000 69000 70000 71000 72000 73000 74000 75000 76000 77000 78000 79000 80000 81000 82000 83000 84000 85000 86000 87000 88000 89000 90000 91000 92000 93000 94000 95000 96000 97000 98000 99000 100000 101000 102000 103000 104000 105000 106000 107000 108000 109000 110000 111000 112000 113000 114000 115000 116000 117000 118000 119000 120000 121000 122000 123000 124000 125000 126000 127000 128000 129000 130000 131000 132000 133000 134000 135000 136000 137000 138000 139000 140000 141000 142000 143000 144000 145000 146000 147000 148000 149000 150000 151000 152000 153000 154000 155000 156000 157000 158000 159000 160000 161000 162000 163000\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "\n",
    "for x in google_news_dictionary_article_text.values():\n",
    "    if counter % 1000 == 0:\n",
    "        print counter,\n",
    "\n",
    "    \n",
    "    # --------------------- For the text file ----------------------------------------------\n",
    "    # Getting information to write the file\n",
    "    article_text = x[\"article_text\"].encode('utf-8').strip()\n",
    "    text_path = \"../Resources/Data/Derived/Google_Texts/\" + str(counter) + \".txt\"    \n",
    "\n",
    "    # Writing the file w/ text\n",
    "    filehandle = open(text_path, \"w\")\n",
    "    filehandle.write(article_text)\n",
    "    filehandle.close()\n",
    "\n",
    "    # --------------------- For the metadata file ----------------------------------------------    \n",
    "    # Saving the rest of the article's metadata as a json file\n",
    "    metadata_path = \"../Resources/Data/Derived/Google_Texts/\" + str(counter) + \"_metadata.json\"    \n",
    "    article_metadata = x.copy()\n",
    "    try: # Not all articles have an \"_id\" key\n",
    "        article_metadata[\"_id\"] = JSONEncoder().encode(article_metadata[\"_id\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Writing    \n",
    "    with open(metadata_path, 'wb') as outfile:\n",
    "        json.dump(article_metadata, outfile)        \n",
    "     \n",
    "    # ----------------------------------------------------------------------------------------------------------------    \n",
    "    counter += 1    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! Great -- now all the dictionary contents have been saved into smaller files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_news_texts_only = pickle.load( open( \"../Resources/Pickles/google_news_texts_only.pickle\", \"rb\" ) )\n",
    "print len(google_news_texts_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_news_texts_only[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump( favorite_color, open( \"save.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
