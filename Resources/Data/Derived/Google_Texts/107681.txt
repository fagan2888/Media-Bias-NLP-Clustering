Topics: alternative medicine, Doctors, Editor's Picks, Erika Janik, Marketplace of the Marvelous, Medicine, Science, Innovation News, Technology News, Life News

On an October evening in 1893, homeopaths from the Hahnemann Medical College marched proudly down the streets of Philadelphia in the city’s annual medical parade. Cheered on by the crowd lining the streets, the students carried canes and waved banners in the royal blue and burnt orange of their school, proudly displaying their motto: “In things certain, unity; in things doubtful, liberty; in all things, charity.” Unity and charity were far from the minds of the medical students at the University of Philadelphia, Jefferson, and Medico-Chirurgical colleges, however. After learning that the Hahnemann students were to lead the parade, the regular students flatly refused to participate, claiming that to do so would insult “their health and dignity.” And so the homeopaths from Hahnemann along with students from the Philadelphia Dental College marched down Broad Street alone to the taunts of their regular peers: “Sugar pill, sugar pill, / Never cured and never will. / Rickety roup, rickety roup, / Hahnemann, Hahnemann, in the soup.” Led by a brass band and a squad of mounted police called in to keep order, the 250 defiant and proud homeopathic students called out their school cheer as they passed: “Rah, rah, rah, Hahnemann, Hahnemann, sis boom ah.” It was a sweet moment for homeopaths, and yet another reminder to regulars that after nearly a century, the fight to vanquish their irregular competitors was far from won.

But American medicine had changed substantially in that century. The discovery of germs, the advent of X-rays, and the growth of sterile surgery among other medical innovations began to shift healing away from individual Americans and the home and into the hands of trained experts working in hospitals. Knowledge about the structure and function of the body had finally reached the point where daily medical practice began to change. These developments could not have come at a better time.

The closing decades of the nineteenth century brought major upheavals to nearly every aspect of life. The horrors of the Civil War had shattered the peaceful vision social reformers had promulgated earlier in the century of humanity’s perfection through right living and self-control. Americans still thought it was important to work toward the common good, but to survive and thrive now seemed to demand risk and self-indulgence rather than personal example and self-sacrifice. Many people, especially the newly wealthy, became philanthropists and donated money to causes as the nation’s now well-developed consumer ethos encouraged people to believe that good works—like good health—could be purchased. Meanwhile, immigration brought millions of new people to the United States just as the nation’s workforce shifted from predominantly rural and farm labor to urban and industrial work. Cities exploded. Advances in transportation and communication networks lessened geographical distances and reduced isolation. Technology also made work more productive and efficient. As a result, business boomed. Economic fortunes were made and lost overnight. At the same time, at least half of all workers barely made enough money to survive.

To a nation in flux and looking for answers, scientific progress appeared to be a cultural cure-all. Science held the promise of order and efficiency at a time when the nation seemed to many Americans unable to cope with the disorder and complexities of modern life. In response, nearly all fields began adopting more systematic methods and making claims of specific knowledge and expertise. Medicine, law, journalism, education, and even child rearing increasingly set boundaries defining the scope of their subject and the prerequisites for practicing.

Regular doctors had tried to set these boundaries and stake their claim on medical practice throughout the nineteenth century but to little effect. Many Americans, aided by the loud shouts of irregulars, had dismissed their argument as more mercenary than scientific, a self-interested effort to dissuade people from seeking the services of competitors—and they likely had a point. But advances in medical science now began to change the healing landscape. No longer just rhetoric, regular medicine had new tools and knowledge at its disposal that offered a tangible hope of healing. Americans did not lose their attachment to self-reliance, but many problems now seemed bigger than any one individual could possibly grasp through common sense alone. In this culture, expertise became a trait of increasing popular value. The unwillingness of some irregulars, namely hydropaths, Thomsonians, and mesmerists, to distinguish between formally trained practitioners and those who came to the field through a calling or hands-on experience now made them appear backward and less well equipped to compete with this new class of professional healers.

These scientific advances and cultural shifts fueled the revival of the medical licenses deemed undemocratic earlier in the century. In the 1880s and 1890s, most state legislatures reinstated licensing requirements at the instigation of regular medicine’s state and local societies. Until late in the century, these medical societies had largely proved ineffective at lobbying for the profession, torn apart by internal struggles over theory, practice, and leadership. These organizations grew stronger and more effective with time, and they succeeded in convincing politicians that medicine demanded a basic competency in science. By the late nineteenth century, the image of the ideal doctor had expanded to include laboratory methods rather than bedside manner and observation alone. These licensing laws did not drive irregulars out of practice, however. Homeopaths and the eclectic heirs to Thomsonism were too well established and the homeopaths far too popular to be suddenly outlawed. Regulars only succeeded in getting the licensing laws they wanted by allowing homeopaths and eclectics—the very groups they had originally organized to oppose—to be licensed as well. By the 1920s, many states had passed licensing statutes that covered newer irregular systems too, though it would be many decades until osteopathy and chiropractic achieved legal protection in every state.

Buoyed by the return of medical licensure, the American Medical Association took a far more active political role in the early twentieth century. While still concerned with berating and exposing irregular quackery, the organization also seized on widespread concerns about the dangers of urban life to campaign for sanitation laws, public hospitals, and the creation of a national health bureau to implement and coordinate public health programs. They supported diagnostic tests for cholera and vaccination for diphtheria and required reporting of tuberculosis and other infectious diseases to city and state officials. Associating themselves with these concerns helped to forge an image of regular medicine as a proponent of social welfare and community health at a time when public health had itself because a distinct field of medicine out of concern over urban life. Improving public health could only improve the status of regular medicine in the eyes of patients and the government. The AMA fought to exclude irregulars from this new arena of health care by lobbying to prevent them from serving on medical councils and city boards of health and in public hospitals, efforts in which they mostly succeeded. Irregulars protested what they saw as political moves by regulars to monopolize public health and to destroy competition on the national level. Regular medicine’s enthusiastic embrace of sanitation and hygiene was an especially paradoxical outcome for the hydropaths who had pioneered the principles and practices that underlay these public health campaigns.

Regulars also pushed for educational reforms in the nation’s medical schools. At the recommendation of the AMA, the Carnegie Foundation for the Advancement of Teaching sent high school principal Abraham Flexner to evaluate the ability of regular, eclectic, homeopathic, and osteopathic schools in the United States and Canada to produce doctors trained in regular methods. The famous Flexner report of 1910 revealed the sorry state of medical education. Flexner wrote complete analyses of each school. Of the 155 he visited, he recommended that 120 schools should close. Flexner declared the majority of the regular schools “utterly wretched” and “hopeless affairs” and discounted all irregular institutions as “worthless” and “fatally defective.” He found most schools to be proprietary or commercial medical enterprises with minimal academic standards and little or no connection to the hospitals and laboratories that had increasingly become central to the provision of care. In the competitive rush to attract students, many proprietary medical schools, regular and irregular alike, had shortened terms and eliminated staff (or never hired them in the first place) to maximize profits. Although he had few kind words for regular schools, Flexner saved his particular scorn for irregulars. He warned that opening the profession to anyone who wanted to be a doctor endangered the well-being of society and the nobility of a profession dedicated to service.

The Flexner report quickly achieved mythic status for catalyzing the reform of medical education in the United States, but its methods and conclusions, particularly concerning irregulars, do raise questions. Who could be surprised that irregular schools did not turn out regular physicians? That was not the goal of an irregular medical education. Flexner was also accompanied in his survey by regular doctor Nathan P. Cowell, secretary of the Council on Medical Education of the AMA. Hardly a disinterested party with regard to the outcome of the report, Cowell’s council had in fact set the standards Flexner used to assess the schools, and the AMA had never seen irregular schools as anything but counterfeit. That’s not to say that the nation’s medical education did not need improvement—better-trained doctors would result in better medicine—but the political and economic motivations of those behind the Flexner report provided just as much if not more motivation than any idealistic appeals to improve the quality of medical education.

In the wake of the report, nearly half of the nation’s regular medical schools closed. Many schools that admitted women and African Americans, which tended to be weaker and financially unstable to begin with, closed. Those that survived drastically upgraded standards. Flexner had recommended that all medical schools require entrants to have a college degree and encouraged the adoption of a four-year medical curriculum. As encouragement, he persuaded the Rockefeller Foundation to make grants to those schools he hand-selected as worthy of investment. He chose mostly long-established institutions in the East as well as a handful in the South, Midwest, and West. Rockefeller’s contributions stimulated other donations to support medical education. Many irregular schools also improved their curriculum to match the new standards of regular medicine. While some of these irregular schools carried on, many failed, done in by the high costs of upgrading facilities and hiring high-quality staff. The net effect of the Flexner report was to widen rather than narrow the gap between the best and worst schools.

Not every irregular kowtowed to Flexner’s findings. Chiropractors, in particular, protested his recommendations. They argued that the adoption of Flexner’s educational standards would exclude worthy but financially strapped students from becoming doctors. In the past, a lower-class person could become a doctor through hard work and desire. Under Flexner’s plan, he or she would stand little chance because of the costs of obtaining both a college and medical education.

The chiropractors did have a point. Requiring college degrees for medical school admittance excluded a majority of the population: more than 90 percent of Americans did not have bachelor’s degrees even by 1920. Longer and more costly training made medicine more exclusive and less accessible to minorities, women, immigrants, and working-class Americans. Flexner, for his part, likely thought curbing enrollment a laudable goal of educational reform. He warned that awarding too many medical degrees only suppressed salaries and limited the field’s ability to attract the best students. “It is evident that in a society constituted as our modern states,” wrote Flexner, “the interests of the social order will be served best when the number of men entering a given profession reaches and does not exceed a certain ratio.” Raising standards was an effective means of reducing the number of doctors and increasing the social and economic status of the profession. Unlike many of his peers who believed female doctors would also lower medicine’s status, Flexner actually supported coeducation in medical schools, though he rather myopically editorialized, “[N]ow that women are freely admitted to the medical profession, it is clear that they show a decreasing inclination to enter it.”

The path was hardly free and clear for women. Flexner speculated that fewer women entered medicine either due to a drop in demand for women doctors or less interest among women in becoming doctors. Neither was true. The closure of irregular medical schools and close alignment of others with regular medicine had a particularly detrimental effect on the women who achieved professional medical careers in irregular health care. Middle- and upper-class women had made great strides in the late nineteenth century, comprising 10 percent or more of enrollment at regular medical schools. While many attended female-only medical colleges, women still made up nearly 20 percent of the medical profession in eastern cities like Boston, New York, and Baltimore by 1900. But lacking adequate financial support, especially as medicine became more technologically sophisticated, many of these schools closed in the late nineteenth and early twentieth centuries. The result was a sharp decline in female medical students even before Flexner issued his report. Coeducation remained an option, and one that many women themselves wanted, but regulars did not make it easy. Oliver Wendell Holmes acknowledged that women brought something unique to healing, but he stopped short of endorsing women’s professional participation in his field. “I have often wished that disease could be hunted by its professional antagonists in couples—a doctor and a doctor’s quick witted wife,” wrote Holmes. “For I am quite sure there is a natural clairvoyance in a woman which would make her . . . much the superior of a man in some particulars of diagnosis.” Holmes was sure that “many a suicide would have been prevented if the doctor’s wife had visited the day before it happened. She would have seen in the merchant’s face his impending bankruptcy while her stupid husband was prescribing for his dyspepsia and endorsing his note.”

Regular medical schools routinely failed to provide opportunities to women and habitually limited the number of women they would even accept at a token 5 percent until the mid-twentieth century. School administrators justified excluding qualified women by claiming that most would give up their medical practices after marriages, so they were not worth the investment. Even those men who seemed to support women’s participation in the field betrayed certain biases about women. John Dodson, dean of Rush Medical College in Chicago, praised his school’s female students as “a credit to themselves and to us” but concluded that “no matter how superior these students may have been in their college work,” they “cannot but do otherwise than rejoice when matrimony claims them.” A medical education also cost more as schools passed the expense of new equipment and faculty, expanded facilities, and lengthened training time on to students. Many women who had once financed their medical education by working could no longer afford to do so. At the same time, the propriety of men and women studying the human body together in the same room remained a potent and divisive issue.

It seems not far-fetched to say that women’s involvement in irregular health systems from the very beginning provided all the evidence some regular doctors needed to dismiss it. In 1893, Harvard professor Edward H. Clarke warned that excessive intellectual activity diverted a woman’s limited supply of energy from reproduction to the brain, which threatened not only her health but also that of her family and society. It was true that women could pursue the same educational course as men, Clarke declared, but “it is not true that she can do all this, and retain uninjured health and a future secure from neuralgia, uterine disease, hysteria, and other derangements of the nervous system.” Worse, women engaging in men’s work “unsexed” themselves by taking on male roles, and thus supposedly male traits, rendering them unable to have the children that would sustain civilization.

Medical texts touting the terror of women’s equality and autonomy flourished. Many used scientific and medical language to rationalize women’s exclusion from active public and professional roles. Dr. Alfred Stille, in his presidential address to the American Medical Association in 1871, declared, “Certain women seek to rival men in manly sports, and the strong-minded ape them in all things, even in dress. In doing so, they may command a sort of admiration such as all monstrous productions inspire, especially when they tend towards a higher type than their own.” The reverse was also true, though: those men who performed the same tasks as women lost their masculinity. Dr. Stille warned that “a man with feminine traits of character or with the frame and carriage of a female is despised by both the sex he ostensibly belongs to and that of which it is at once a caricature and a libel.” Working with women or spending too much time in the feminizing clutches of mothers, teachers, and wives sapped a man’s masculinity. These societal assumptions could not help but influence perceptions about irregular health systems, particularly those like hydropathy and homeopathy where women took active leadership roles. With women in charge, irregular health was marked as both dangerous and ridiculous.

Even with these barriers, women did not stop practicing medicine. Osteopaths, chiropractors, and Christian Scientists welcomed women into their professional fold. Other women, particularly homeopaths, organized locally and focused on lay practice through the first half of the twentieth century. Still more entered regular medicine in nursing and social work, careers that closely aligned with cultural assumptions about women’s more caring nature, and as such were structurally subordinated to the mostly male doctors.

The AMA’s gains and control of public health along with the quickening pace of medical advances in the first decades of the twentieth century significantly challenged the strength of irregular medicine. The introduction of the first antimicrobial drugs, known as sulfonamides, in the 1930s presented a significant breakthrough in the fight against infectious disease and paved the way for the antibiotic revolution in medicine. The mass production of penicillin in the 1940s nearly eliminated diseases that had plagued humans for centuries, including syphilis, meningitis, and rheumatic fever. Streptomycin in 1945 dramatically reduced cases of tuberculosis and plague. Even better, these drugs were some of the first non-homeopathic remedies to cause few side effects. Americans clamored for these “wonder drugs,” and doctors dispensed them with what historian James Whorton has called “antibiotic abandon.”