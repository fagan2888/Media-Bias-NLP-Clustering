{"article_title": "DevOps Best Practices: Was wir aus Obamacare lernen k\u00f6nnen", "article_keywords": ["fr", "die", "der", "obamacare", "devops", "best", "knnen", "werden", "aus", "practices", "und", "wir", "den", "oder", "zu", "von", "lernen", "sich"], "article_url": "https://jaxenter.de/devops-best-practices-was-wir-aus-obamacare-lernen-konnen-198", "article_text": "Best Practices f\u00fcr performanceoptimierte DevOps\n\nEtwa 80 Prozent der kritischen IT-Probleme werden von nur 20 Prozent aller Ursachenmuster ausgel\u00f6st. Dies zeigen diverse Untersuchungen und Expertendiskussionen. Die meisten Ursachenmuster h\u00e4ngen dabei mit Performance- oder Architekturproblemen in der Applikation selbst oder der darunter liegenden Infrastruktur zusammen. Die Folge: Gem\u00e4\u00df einer aktuellen Studie werden 80 Prozent der Entwicklungszeit mit der Erkennung und Behebung von Problemen verschwendet. Daraus resultieren alleine in den USA gesch\u00e4tzte Gesamtkosten von etwa 60 Milliarden Dollar pro Jahr. Und dieser Aufwand f\u00fcr die Fehlersuche d\u00fcrfte sich aufgrund der steigenden Komplexit\u00e4t durch Cloud-Angebote sowie der immer schnelleren App-Entwicklung vor allem f\u00fcr Mobilger\u00e4te weiter erh\u00f6hen. Oft noch schlimmer als der finanzielle Verlust schmerzt aber der durch Abst\u00fcrze und lange Reaktionszeiten ruinierte Ruf des Anbieters.\n\nEmpfehlenswerte DevOps-Vorgehensweisen\n\nEs gibt viele Definitionen von DevOps. Der wichtigste Aspekt ist die \u201egelebte\u201c Kollaboration aller Entscheider in Softwareentwicklung, Test und Betrieb und die gemeinsame Verantwortung f\u00fcr alles, was zum Erfolg der Software f\u00fchrt. Das bedeutet, dass der Betrieb der Entwicklung zu verstehen gibt, wie die Betriebsumgebung wirklich aussieht, in der die Anwendung in Zukunft laufen wird und was es bedeutet, wenn Fehler auftreten. Der Betrieb wiederum muss sowohl den Testern als auch den Entwicklern dabei helfen, eine betriebs\u00e4hnliche Umgebung zur Verf\u00fcgung zu stellen. Die Entwickler m\u00fcssen sich dazu verpflichten, dass ihre Software in dieser Umgebung stabil l\u00e4uft.\n\nEine Ausrede wie \u201eEs l\u00e4uft auf meiner Maschine\u201c gibt es dann nicht mehr. Au\u00dferdem sind die Entwickler gefordert, dem Betrieb dabei behilflich zu sein, automatische Deployment-Tools zu entwickeln, die sicherstellen, dass beim Aufziehen neuer Versionen nichts \u00fcbersehen wird. Leider gibt es viele prominente Gegenbeispiele, bei denen genau das \u00fcbersehen wurde. Diese k\u00f6nnten zuk\u00fcnftig verhindert werden. Im n\u00e4chsten Schritt gilt es zusammen zu definieren, welche Daten aus dem Betrieb f\u00fcr Entwicklungs- und Testabteilung zugreifbar sind und welche Tools daf\u00fcr verwendet werden. Mit diesen Daten kann man im Fehlerfall schneller auf Probleme reagieren. Au\u00dferdem k\u00f6nnen die Tester ihre Testszenarien um reale Anwendungsf\u00e4lle erweitern.\n\nEin prominentes Problembeispiel ist die Internetseite von \u201eObamacare\u201c f\u00fcr den Zugang zur Krankenversicherung in den USA.\n\nTrotz jahrelanger Vorbereitung st\u00fcrzte sie kurz nach dem Start Ende 2013 mehrmals und nachhaltig ab. Um solche Peinlichkeiten zu vermeiden, sollte die Entwicklung von Anwendungen mit schlanken, flexiblen und l\u00f6sungsorientierten Methoden erfolgen. Vor allem DevOps zur Integration von Entwicklung und Betrieb der Software bietet sich hierf\u00fcr an, sollte aber mit einem Fokus auf Performance und kurze Reaktionszeiten aus Sicht des Nutzers erweitert werden. Doch was bedeutet das genau und wie l\u00e4sst sich das umsetzen?\n\nAufmacherbild: Magnifying glass over Obamacare policy and piggy bank von Shutterstock / Urheberrecht: zimmytws\n\n[ header = Seite 2: Diagnose der Obamacare-Webseite ]\n\nDiagnose der Obamacare-Website\n\nNicht nur in den USA beherrschte der politische Streit \u00fcber die neu eingef\u00fchrte Pflicht zur Krankenversicherung die Schlagzeilen. Nach jahrelangen Diskussionen und diversen Gerichtsurteilen wurde Ende 2013 die Registrierungsmaske auf healthcare.gov f\u00fcr alle US-B\u00fcrger freigeschaltet. Kaum online, war sie aber auch schon wieder offline, denn sie hielt dem Ansturm der Eintragungswilligen nicht einmal ansatzweise stand. Das Portal wurde auch in den Wochen danach von Abst\u00fcrzen, Blackouts, inaktiven Links und unverst\u00e4ndlichen Fehlermeldungen dominiert. Schnell waren vier vermeidbare Fehler des neuen Portals identifiziert:\n\ndie gro\u00dffl\u00e4chige Nutzung von Inhalten, die durch Drittanbieter bereitgestellt wurden das Fehlen von Web Performance Optimization (WPO) und grundlegender Best Practices prozessaufw\u00e4ndiges JavaScript langsame serverseitige AJAX Requests\n\nSelbst nach dem anf\u00e4nglichen Komplettzusammenbruch hatten die IT-Verantwortlichen in den folgenden Wochen nicht viel auf der Website \u00e4ndern lassen. Nur aufgrund der geringer werdenden Nutzerzahlen stabilisierte sich das Angebot ein wenig. Dabei h\u00e4tten ein paar einfache Ma\u00dfnahmen gen\u00fcgt, um die Website dauerhaft und zuverl\u00e4ssig zu stabilisieren.\n\nBei den Inhalten von Drittanbietern fiel beispielsweise auf, dass healthcare.gov verschiedene Real-User-Monitoring-L\u00f6sungen nutzte. Daf\u00fcr mag es zwar gute Gr\u00fcnde geben, doch eine Konsolidierung der L\u00f6sungen sowie die Nutzung eines Monitoring-Tools, das viele Funktionen und Anwendungsm\u00f6glichkeiten bietet, h\u00e4tte die Performance deutlich erh\u00f6ht. Die Missachtung grundlegender Best Practices sah man beispielsweise an dem mit 350 KB sehr gro\u00dfen Hintergrundbild auf der Homepage. Mit kostenlosen Bildbearbeitungsprogrammen lie\u00dfe es sich ohne Qualit\u00e4tsverlust um mehr als 70 Prozent auf 99 KB reduzieren.\n\nSogar 80 Prozent der JavaScript-Inhalte lie\u00dfen sich reduzieren. Auf den meisten Seiten befanden sich zahlreiche JavaScript-Dateien \u2013 alleine 65 (!) auf der myAccount-Seite. Die Registrierungsseite enthielt sechzehn jQuery-bezogene JavaScript-Dateien mit einem Gesamtvolumen von 1 MB. Die meisten dieser jQuery-Dateien waren Entwickler- und Debug-Versionen, die noch s\u00e4mtliche Kommentare enthielten. Die Zusammenfassung und Minimierung der JavaScript-Dateien h\u00e4tte schnell zu h\u00f6herer und zuverl\u00e4ssigerer Performance gef\u00fchrt. Alleine die Datei jQuery.DataTables.js w\u00e4re durch einen \u00f6ffentlich verf\u00fcgbaren Minimierer wie JS Compress [1] von 440 auf 83 KB geschrumpft.\n\nZumindest bei den AJAX-Aufrufen waren nach wenigen Wochen Verbesserungen erkennbar. W\u00e4hrend sie anfangs bis zu 16,8 Sekunden dauerten und mehrmals durchgef\u00fchrt wurden, waren sie sp\u00e4ter deutlich schneller. Ob dies an einer echten Verbesserung der serverseitigen Performance lag oder an der geringeren Arbeitslast der Webseite durch eine h\u00f6here Abbruchrate der Nutzer, lie\u00df sich nicht ohne gr\u00f6\u00dferen Aufwand ermitteln.\n\nAn der Nachhaltigkeit von Verbesserungen waren zumindest leichte Zweifel angebracht. Wenige Wochen nach dem Go-Live hat Compuware den Nutzern in einem Fernsehinterview empfohlen, die neuesten Browserversionen zu verwenden, die schnellere JavaScript und Rendering Engines besitzen. In einem Test war klar erkennbar, dass etwa der Internet Explorer 10 deutlich schneller beim Parsing und der Ausf\u00fchrung von JavaScript war als die Version 9.\n\n[ header = Seite 3: Lektionen aus Obamacare ]\n\nLektionen aus Obamacare\n\nDie Verantwortung f\u00fcr die vern\u00fcnftige Nutzung einer Website sollte nie auf den Anwender abgew\u00e4lzt werden. So muss erst der Anbieter seine Hausaufgaben erledigen und die WPO Best Practices befolgen. Dazu geh\u00f6ren:\n\nDie m\u00f6glichst sparsame Nutzung von Inhalten, die \u00fcber Drittanbieter bereitgestellt werden Umfassende WPO und die Befolgung grundlegender Best Practices wie minimierte Bild-, JavaScript- und CSS-Dateien Zusammenfassung verschiedener JavaScript-Dateien und deren Reduzierung Schnelle serverseitige AJAX Requests\n\nMit diesen einfachen Mitteln erreicht der Anbieter in der Regel bereits schnell deutliche Verbesserungen. Anschlie\u00dfend empfiehlt sich ein umfassendes Application-Performance-Management zur weiteren Erh\u00f6hung von Geschwindigkeit und Zuverl\u00e4ssigkeit der Anwendungen. Dazu geh\u00f6rt die Einf\u00fchrung von synthetischem SLA-Monitoring zur \u00dcberwachung verschiedener Regionen sowie von Real User Monitoring zur Kontrolle der Performance aus Sicht des Nutzers. Beim synthetischen Monitoring werden an verschiedenen Stellen im Netzwerk und im Rechenzentrum Roboter installiert, die automatisch in definierten Intervallen immer wieder die gleiche Transaktion ausf\u00fchren.\n\nDies zeigt aber nur die grunds\u00e4tzliche Funktionsf\u00e4higkeit der Komponenten. Ein echter Anwender hat dagegen ein v\u00f6llig anderes Nutzungsverhalten. So werden beim Real User Monitoring tats\u00e4chliche Nutzer in die Analyse einbezogen. Dazu sind \u201eMessf\u00fchler\u201c im Netzwerk installiert, um die Performance von Transaktionen aus Anwendersicht zu \u00fcberwachen. Aus den eingehenden Datenpaketen lassen sich somit die Performancewerte s\u00e4mtlicher Transaktionen f\u00fcr jeden Standort sowie jedes Ger\u00e4t ermitteln und analysieren. Dies erm\u00f6glicht einen detaillierten Einblick in die Performance jeder Infrastrukturschicht wie Anwendungsserver oder Load Balancer sowie die Korrelation zwischen dem Datenverkehr im Frontend und Backend von Applikationen und der unterst\u00fctzenden Netzwerkinfrastruktur.\n\n\u00dcber ein entsprechendes Dashboard k\u00f6nnen IT- und Businessverantwortliche dann genau erkennen, wie viele Nutzer, welche Standorte oder gar welche Transaktionen von einem konkreten Problem betroffen sind und welchen m\u00f6glichen Einfluss dieses auf Gesch\u00e4ftsprozesse hat. Dabei erhalten verschiedene Abteilungsleiter unterschiedliche Sichten, damit sie m\u00f6glichst schnell die Probleme priorisieren k\u00f6nnen. Zudem erm\u00f6glicht die Berechnung von Trends Vorhersagen zur zuk\u00fcnftigen Leistungsf\u00e4higkeit. Auch umfassende, regelm\u00e4\u00dfige Deep-Dive-Sessions lassen sich damit durchf\u00fchren, um den Erfolg von \u00c4nderungen zu kontrollieren.\n\nF\u00fcr eine ausreichende Performance der ausgelieferten Anwendungen ist die gesamte Lieferkette einzubeziehen, vom Rechenzentrum oder der Cloud bis hin zum Endger\u00e4t des Nutzers, denn an allen Stellen kann die Performance beeintr\u00e4chtigt werden. So sollte eine L\u00f6sung installiert werden, die s\u00e4mtliche Bereiche erfasst und auswertet. Ist dann eine Zuordnung auf einzelne Transaktionen und Nutzer m\u00f6glich, l\u00e4sst sich schnell die tats\u00e4chliche Ursache f\u00fcr Performanceprobleme lokalisieren. Aktuelle Monitoring-L\u00f6sungen zeigen nicht nur die Dringlichkeit in Form von m\u00f6glichen Gesch\u00e4ftsauswirkungen an, sondern geben auch Hinweise zur Behebung und k\u00f6nnen die schnelle Probleml\u00f6sung unterst\u00fctzen, ohne dass der Anwender etwas davon bemerkt.\n\nPerformance von Anfang an testen\n\nBetrachtet man die Hauptgr\u00fcnde daf\u00fcr, warum Anwendungen langsam und instabil sind oder Entwicklungsteams sehr viel Zeit f\u00fcr die Behebung von Problemen sowie die Durchf\u00fchrung von \u00c4nderungen ben\u00f6tigen, f\u00e4llt das fehlende Verst\u00e4ndnis zwischen den Teams auf. Die Voraussetzungen f\u00fcr eine hohe Performance sind nicht allen beteiligten Teams klar und es gibt keine automatische Erfolgsbewertung. Hierf\u00fcr gibt es jedoch eine Reihe von M\u00f6glichkeiten, die bereits erfolgreich in Unternehmen angewendet werden. Damit lassen sich die Ziele aller Teams abgleichen und deren bislang getrennte Arbeitsprozesse miteinander verbinden. Die oberste Priorit\u00e4t lautet dann: h\u00f6chste Softwarequalit\u00e4t f\u00fcr den Nutzer.\n\nDie meisten Probleme bei Anwendungen entstehen in den Bereichen Performance und Stabilit\u00e4t. Daher sollten die entsprechend ben\u00f6tigten Architekturen zu den funktionalen Aufgaben f\u00fcr die agile Entwicklung hinzugef\u00fcgt werden. Beispielsweise sollen 100 Nutzer gleichzeitig eine neue Suchfunktion bedienen k\u00f6nnen und eine Antwort innerhalb einer Sekunde erhalten. Eine Anforderung k\u00f6nnte dann lauten, dass die Anwendung beim Hinzuf\u00fcgen zus\u00e4tzlicher Server skalieren kann und zus\u00e4tzliche Lasten ohne h\u00f6here Antwortzeiten bew\u00e4ltigt.\n\nEiner der Gr\u00fcnde, warum solche Anforderungen nicht bereits w\u00e4hrend der Entwicklung gestellt werden, ist, dass Testbarkeit als Implementierungsaufgabe bei ge\u00e4nderten oder neuen Funktionen fehlt. \u00c4nderungen in der Software unterbrechen h\u00e4ufig Testskripte und eine Wiederherstellung erscheint in vielen F\u00e4llen als zu aufw\u00e4ndig. Die Pr\u00fcfungen finden daher entweder zu sp\u00e4t statt oder werden manuell durchgef\u00fchrt. Entsprechend sollte die Bedienoberfl\u00e4che IDs f\u00fcr Felder nutzen, die nicht durch Layout\u00e4nderungen beeinflusst werden. Zudem sollten URL-Muster oder REST-Oberfl\u00e4chen bei verschiedenen Build-Versionen m\u00f6glichst gleich bleiben. Damit lassen sich Anwendungen schon ab der Fr\u00fchphase der Entwicklung regelm\u00e4\u00dfig und schnell testen.\n\nEine weitere Voraussetzung daf\u00fcr ist, dass sich die Anwendung oder Funktion schnell installieren l\u00e4sst. Die Entwickler m\u00fcssen daher Testern und Betriebsverantwortlichen automatische Installationsprozesse f\u00fcr Softwarekomponenten bereitstellen, die das Set-up von Testumgebungen beschleunigen sowie die Qualit\u00e4t von Produktionsrollouts erh\u00f6hen.\n\n[ header = Seite 4: Devs, Test, Ops und Business m\u00fcssen voneinander lernen ]\n\nDevs, Test, Ops und Business m\u00fcssen voneinander lernen\n\nNeben technischen Optimierungen ist auch eine effiziente organisatorische Basis n\u00f6tig, um schnell auf Ver\u00e4nderungen oder Probleme zu reagieren. In vielen Unternehmen arbeiten die an der Softwareentwicklung beteiligten Bereiche Entwicklung, Test, IT- und Gesch\u00e4ftsbetrieb (Dev, Test, Ops, Business) voneinander getrennt. Die Teams m\u00fcssen jedoch miteinander verbunden werden. Der erste Schritt besteht darin, Test und Ops zu den t\u00e4glichen Entwicklermeetings einzuladen. So erfahren sie, woran gerade gearbeitet wird und was geplant ist. Die Devs sollten auf das Feedback der anderen Abteilungen h\u00f6ren und es in die Aufgaben einbauen, z. B.: \u201eEntwicklung einer automatischen Deployment-Option f\u00fcr Funktion XYZ\u201c oder \u201eneue REST-Schnittstelle TESTABLE\u201c. Auch bei der Architektur sollte der externe Input ber\u00fccksichtigt werden, etwa Anregungen dazu, welche Datenbanken oder Logging-Server w\u00fcnschenswert sind.\n\nEntwickler k\u00f6nnen von Testern und IT-Betrieblern einiges lernen, weil diese Erfahrungen zu Performance, Skalierbarkeit und Deployment-Szenarien besitzen. Andererseits k\u00f6nnen Tester und Ops von den Devs lernen, wie automatische Deployment-Tools f\u00fcr Test- und Produktionsumgebungen erstellt werden. Damit verringern sie den Aufwand f\u00fcr jedes neue Test- oder Produktions-Deployment. Eine enge Zusammenarbeit gem\u00e4\u00df DevOps erm\u00f6glicht es allen Teams, die ben\u00f6tigten Tools zur Messung von Performance und Skalierbarkeit neuer Funktionen sowie zum Sammeln von Diagnoseinformationen oder Erfolgsmessungen f\u00fcr das Business zu ermitteln. Die gemeinsame Verwendung dieser Tools erh\u00f6ht die Akzeptanz der Messergebnisse und verbessert die Zusammenarbeit zwischen den Teams. So werden die Verst\u00e4ndnisl\u00fccken zwischen Test, Dev, Ops und Biz geschlossen. Zudem verhindert diese enge Zusammenarbeit auch das \u00fcbliche Schwarze-Peter-Spiel, in dem die Verantwortung f\u00fcr Fehler zwischen den Abteilungen hin- und hergeschoben wird, ohne dabei einen konkreten L\u00f6sungsversuch zu entwickeln.\n\nFortschritt und Erfolg lassen sich aber nur anhand \u00fcberpr\u00fcfbarer Fakten messen. Code Coverage etwa sagt Entwicklern und Testern, wie gut ihre Testumgebung ist. Zudem wollen Ops wissen, ob sie zumindest so hoch ist wie bei der letzten erfolgreichen Installation. Die Messung und Ver\u00f6ffentlichung dieser Werte f\u00fcr alle beteiligten Teams ist wichtig, damit diese die Auswirkung ihrer Arbeit auf die Ziele anderer Teams besser verstehen. Zudem f\u00f6rdert dies das Vertrauen, dass die T\u00e4tigkeiten anderer Abteilungen sie bei der Erreichung ihrer eigenen Ziele unterst\u00fctzen.\n\nAus Sicht der Entwickler sollten beispielsweise die eingangs erw\u00e4hnten Problemmuster vermieden werden. Falls bekannt ist, dass die Ausf\u00fchrung zu vieler Datenbankabrufe pro Anfrage ein Problem darstellt, sollte die Anzahl der Datenbankprozesse f\u00fcr alle Produkt- und Integrationstests gemessen werden. Ein Fr\u00fchwarnsignal f\u00fcr Ingenieure ist die Erh\u00f6hung des SQL Counts aufgrund aktueller Code\u00e4nderungen. Erh\u00e4lt der IT-Betrieb die entsprechenden Zahlen und sieht er dadurch, dass der Datenbankverkehr trotz neuer Funktionen nicht erh\u00f6ht wird, muss er auch nicht prophylaktisch die Kapazit\u00e4t der Datenbankserver erweitern.\n\nF\u00fcr den Betrieb ist es auch wichtig, Installationen schnell und erfolgreich durchzuf\u00fchren. So stellt die Deployment-Zeit ein entscheidendes Kriterium dar, das deutlich durch neue Funktionen und Architekturen beeinflusst wird. Falls sich die Installationszeit dadurch erh\u00f6ht oder zu viele Abst\u00fcrze ausgel\u00f6st werden, m\u00fcssen diese den Entwicklern kommuniziert werden. Weitere wichtige Kriterien sind z. B. Antwortzeiten, MBs pro Nutzung, Anzahl der Log-Zeilen oder Dauer der Wiederherstellung.\n\nWeitgehende Automatisierung\n\nDie \u00fcbergreifende Zusammenarbeit der Teams nach DevOps f\u00fchrt zu einer beschleunigten Entwicklung von Anwendungen und Funktionen, um schneller auf Probleme oder Marktanforderungen reagieren zu k\u00f6nnen. Um noch schneller zu werden, ist ein hohes Ma\u00df an Automatisierung n\u00f6tig, denn jeder manuelle Prozess kostet Zeit. Daher ist es wichtig, alle bislang erw\u00e4hnten Bereiche zu automatisieren, seien es die Performance- und Skalierbarkeitstests, Deployments oder Skalierungsm\u00f6glichkeiten. Das bedeutet auch, dass die von jedem Team definierten Metriken automatisch ermittelt und an jeden beteiligten Mitarbeiter kommuniziert werden.\n\nDaher sollten Unternehmen in Testtools investieren, die sich einfach integrieren lassen und automatisch Performancewerte wie Antwortzeiten oder Architekturwerte wie die Anzahl der SQL Statements liefern. Dies erfordert Tools, die automatische B\u00fcndelung und Deployments sowie Rollbacks erlauben. Die entsprechenden Tools sollten die Ergebnisse automatisch an einem zentralen und einfach zug\u00e4nglichen Ort ver\u00f6ffentlichen, etwa einem Wiki oder Ticketsystem. Das Ziel lautet daher, m\u00f6glichst alle Aufgaben entlang der Entwicklungs- und Deployment-Pipeline zu automatisieren.\n\nWie sollte man damit anfangen? Am besten mit der Identifizierung der aktuell h\u00e4ufigsten und wichtigsten Problemursachen. Anschlie\u00dfend sollte man herausfinden, wie sich diese Probleme bereits in der Entwicklung erkennen lassen. Welche Messungen sind dann n\u00f6tig, um diese Performance- und Architekturprobleme zu identifizieren? Welche Tests sind n\u00f6tig, um diese Fehler zu erfassen? Und wie l\u00e4sst sich der Code \u00fcberwachen, um diese Probleme zu erfassen und sie automatisch an die Verantwortlichen weiterzuleiten? Erst wenn alle diese Fragen beantwortet und die entsprechenden L\u00f6sungen umgesetzt sind, f\u00fchrt DevOps tats\u00e4chlich zu einer bereits w\u00e4hrend der Entwicklung optimierten Anwendungsperformance.\n\nTo-dos f\u00fcr optimiertes DevOps\n\n\u2013 \u201eGelebte\u201c Kollaboration, z. B. durch gemeinsame Stand-up-Meetings (t\u00e4gliche Kurzbesprechungen, meist im Stehen)\n\n\u2013 Automatisierung von Testen, Deployment und Monitoring\n\n\u2013 Betriebs\u00e4hnliche Umgebung f\u00fcr Entwickler und Tester\n\n\u2013 Definierte Abnahmetests, bevor in den Betrieb ausgefahren wird\n\n\u2013 Gemeinsam entwickelte Deployment-Tools\n\n\u2013 Gemeinsam definierter Monitoring-Ansatz f\u00fcr den Betrieb", "article_metadata": {"og": {"site_name": "JAXenter", "description": "<p class=\"SuSSubhead2\">Abgest\u00fcrzte Websites, Anwendungen im Schneckentempo, \u00e4rgerliche Funktionsfehler: Schon bei der Entwicklung lassen sich viele Probleme mit der Stabilit\u00e4t und Performance vermeiden. Dazu muss der aktuelle DevOps-Ansatz aber um die Einbindung von Testszenarien und Businessanforderungen erweitert werden.</p>", "title": "DevOps Best Practices: Was wir aus Obamacare lernen k\u00f6nnen - JAXenter", "locale": "de_DE", "image": "https://jaxenter.de/wp-content/uploads/2014/12/devops_obamacare.jpg", "updated_time": "2015-01-26T17:15:08+00:00", "url": "https://jaxenter.de/devops-best-practices-was-wir-aus-obamacare-lernen-konnen-198", "type": "article"}, "article": {"section": "Artikel", "published_time": "2014-12-08T11:00:00+00:00", "modified_time": "2015-01-26T17:15:08+00:00"}, "viewport": "width=device-width, initial-scale=1", "description": "Abgest\u00fcrzte Websites, Anwendungen im Schneckentempo, \u00e4rgerliche Funktionsfehler: Schon bei der Entwicklung lassen sich viele Probleme mit der Stabilit\u00e4t und Performance vermeiden. Dazu muss der aktuelle DevOps-Ansatz aber um die Einbindung von Testszenarien und Businessanforderungen erweitert werden.", "generator": "WordPress 4.1.2"}, "_id": "\"57477af36914bd0286fd1ac8\"", "article_summary": "[ header = Seite 3: Lektionen aus Obamacare ]Lektionen aus ObamacareDie Verantwortung f\u00fcr die vern\u00fcnftige Nutzung einer Website sollte nie auf den Anwender abgew\u00e4lzt werden.\nEin prominentes Problembeispiel ist die Internetseite von \u201eObamacare\u201c f\u00fcr den Zugang zur Krankenversicherung in den USA.\nBest Practices f\u00fcr performanceoptimierte DevOpsEtwa 80 Prozent der kritischen IT-Probleme werden von nur 20 Prozent aller Ursachenmuster ausgel\u00f6st.\nAndererseits k\u00f6nnen Tester und Ops von den Devs lernen, wie automatische Deployment-Tools f\u00fcr Test- und Produktionsumgebungen erstellt werden.\nDie meisten Ursachenmuster h\u00e4ngen dabei mit Performance- oder Architekturproblemen in der Applikation selbst oder der darunter liegenden Infrastruktur zusammen."}