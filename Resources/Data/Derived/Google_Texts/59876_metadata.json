{"article_title": "How To Read The Mind Of A Supreme Court Justice", "article_keywords": ["supreme", "court", "words", "read", "mind", "courtcast", "justice", "doesnt", "arguments", "justices", "cases", "oral"], "article_url": "http://fivethirtyeight.com/features/how-to-read-the-mind-of-a-supreme-court-justice/", "article_text": "Despite the gleaming white building that houses it, the Supreme Court is one of the most powerful black boxes in the country. When it convenes for oral arguments, there are no photos, no videos, no broadcasts.\n\nThat\u2019s not to say we\u2019re clueless about the court\u2019s goings on, of course. Journalists and bloggers attend the arguments and report back to their readers. And if we don\u2019t have photos, at least we have sketches. Some have even turned to clandestine camerawork. Now a new project uses data to get inside the chamber \u2014 and maybe inside the justices\u2019 heads.\n\nMore Politics\n\nSupreme Court oral arguments are exercises in multitasking: The justices are talking to advocates as they\u2019re talking to each other. Chief Justice John Roberts has described the lawyers as \u201cbackboards\u201d \u2014 justices\u2019 questions rebound off the lawyers and back to the other justices. Through their questions, they can signal to the others what they\u2019re thinking. They can also try to persuade. Their target is often Justice Anthony Kennedy, the most common swing vote on the bench.\n\nBut this legal process is also a data-generating process. How many words did Justice Elena Kagan utter? How about Justice Antonin Scalia? To whom were they spoken? What was the sentiment of those words? How many times was the solicitor general interrupted?\n\nChris Nasrallah knows the answers to these questions. He\u2019s used them to create CourtCast, a computer model that predicts Supreme Court decisions based on oral arguments alone.\n\nCourtCast, a machine-learning model, relies only on PDF files of oral argument transcripts. There are three inputs: the number of words spoken by justices to each party, the sentiment of those words, and the number of times a justice interrupts an attorney. That\u2019s really it \u2014 CourtCast doesn\u2019t care about body language, it doesn\u2019t care about justices\u2019 ideologies, and it doesn\u2019t care about who\u2019s arguing the case in front of the court. It doesn\u2019t know the law or the precedent or the political climate. The model trains itself on past cases, learning which justice tendencies are pertinent. It can then analyze the transcript from any fresh case and predict an outcome.\n\n\u201cI\u2019m surprised that nobody\u2019s done this before,\u201d Nasrallah told me over a cappuccino in downtown Manhattan in early March. Armed with a Ph.D. focused on computational biology from University of California, Berkeley and postdoc experience at North Carolina State, Nasrallah is pursuing a career in data science. He built CourtCast to get a job. He wanted to buck the negative stereotypes of academics \u2014 that they work slowly and are oblivious to commercial applications. He\u2019s always been an interested court observer, so researching the subject came naturally. It took him just a few weeks to build CourtCast.\n\nIt isn\u2019t perfect \u2014 far from it. Nasrallah claims a 70 percent accuracy rate, which is both impressive and not. Since John Roberts has been chief justice, the petitioner has won 68 percent of cases, so CourtCast\u2019s 70 percent isn\u2019t exactly better than just picking the favorites. But again, CourtCast is flying nearly blind. It has no idea what a given case is even about; it\u2019s using just the words uttered in one hour of argument.\n\nI\u2019ve written before about other Supreme Court predictors \u2014 law professors, legal practitioners, hobbyists in Queens. Universally, human predictors emphasize the importance of the argument in their predictions. CourtCast, the first attempt I\u2019m aware of to quantify oral argument with a machine model, is different. The patterns it uncovers are simple: When a justice asks questions of a lawyer, it\u2019s bad for his chances \u2014 it means the justice is skeptical and is trying to poke holes. If justices interrupt a lawyer, it\u2019s really bad for his chances \u2014 they\u2019re so skeptical they just can\u2019t wait to poke holes. A Ginsburg interruption is worst of all.\n\nNina Totenberg, NPR\u2019s legal affairs correspondent, said she\u2019d noticed that too. \u201cMore often than not \u2014 or at least there\u2019s a 50-50 chance \u2014 counsel gets interrupted because that justice thinks what counsel just said is unacceptable crap.\u201d\n\nBelow is a sample output from CourtCast for the landmark King v. Burwell Obamacare case. (CourtCast\u2019s code is available on Nasrallah\u2019s Github page, and more detail can be found on his blog.) The bigger the bar, the worse for the side that the bar is on.\n\nThe liberals \u2014 Ginsburg and Justice Stephen Breyer \u2014 asked more of the petitioner and interrupted him a lot more. Bad news for him. The others did the same of the respondent. In the King v. Burwell case, CourtCast gives a 61 percent chance that the government wins and Obamacare subsidies are upheld.\n\nSIDEBAR: CourtCast vs. NPR\u2019s Nina Totenberg: How does a machine interpret a court case differently than a trained pro?\n\nNone of CourtCast\u2019s findings came as a surprise to Adam Liptak, the Supreme Court correspondent for The New York Times. And he\u2019d never heard of Nasrallah or CourtCast.\n\n\u201cTwo things are well known and will get you to 70 percent with your eyes closed,\u201d he told me. \u201cOne is the petitioner wins about two-thirds of the time.\u201d The other: \u201cIf you get a lot of questions, you\u2019re going to lose.\u201d\n\nLiptak may not be blown away by CourtCast\u2019s 70 percent success rate, but that\u2019s OK with Nasrallah for now. At least he\u2019s confirmed the conventional wisdom. \u201cHere we\u2019ve quantified the intuition and the way the justices are acting,\u201d Nasrallah said. And given that he built CourtCast in just a few weeks, he\u2019s confident it can be improved.\n\nLinda Greenhouse, formerly of The New York Times and now a lecturer at Yale, has written explicitly about her predictive prowess. In a 2004 paper, she described how the Supreme Court press corps routinely engaged in predictions, \u201cusually made during the walk down the stairs from the courtroom following an oral argument session,\u201d often with a friendly wager thrown in. She pegged her accuracy, for those cases she was bold enough to write about in the paper, at around 75 percent.\n\n\u201cWhatever Linda\u2019s success rate was, mine is a little better,\u201d Liptak joked.\n\nLiptak and Dahlia Lithwick, Slate\u2019s Supreme Court writer, both emphasized the importance of attending oral arguments rather than just parsing transcripts. Crossed arms, rolled eyes and tone of voice can be telling. And the computer is ignorant of all of that.\n\nDespite its ignorance of body language, CourtCast works in part because of a sea change in the very nature of oral arguments. It thrives on the give-and-take of a \u201chot\u201d bench. Interruptions are important to its predictions, and oral arguments weren\u2019t always interrupted so frequently. Greenhouse noticed this trend covering the court in the 1980s. Former Chief Justice William Rehnquist never had to play argument traffic cop like Roberts does. And Lithwick has noticed it accelerate in the last few years.\n\nJUSTICE WORDS INTERRUPTIONS Sotomayor 522 2.6 Scalia 594 2.4 Breyer 821 2.1 Ginsburg 457 1.5 Roberts 577 1.5 Kennedy 322 1.1 Kagan 501 0.8 Alito 322 0.6 Thomas 0 0\n\nSome credit \u2014 or blame \u2014 for the most recent changes can be given to the Sotomayor Effect. \u201cSotomayor is notorious for being a super-talker,\u201d Lithwick said. \u201cShe interrupts everyone.\u201d Lithwick\u2019s right about the interruptions, but Justice Breyer runs away with the talkativeness crown. (Data is since 2005, and the table shows the average words uttered and interruptions per oral argument, by justice.)\n\nBut CourtCast\u2019s reliance on justice word count and interruptions could render it less effective in the future. Totenberg cautions that though the bench is now fairly hot, it may cool down. Gentler personalities may fill its ranks, and it\u2019s possible \u2014 possible \u2014 that the court may become less polarized. It\u2019s tough to imagine how the algorithm could gain a foothold then.\n\nThe Supreme Court journalists were bullish on CourtCast\u2019s usefulness. \u201cIf I were a Supreme Court advocate, I\u2019m sure I would certainly study this material to get clues as to how to present myself and how to push the right buttons,\u201d said Greenhouse.\n\n\u201cI can\u2019t imagine it\u2019s not incredibly useful to the attorneys and the parties,\u201d said Lithwick.\n\nBut when I talked to a couple attorneys, they said they can already do better than CourtCast. Carter Phillips, a former assistant to the solicitor general and now a partner at Sidley Austin, has argued more cases before the Supreme Court \u2014 80 \u2014 than any lawyer now in private practice. And for Phillips, simple predictions are a snap. He pegs his accuracy for the cases he argues at 90 percent. (Phillips doesn\u2019t keep explicit stats, so this was his post facto estimate.) But even better than him, he says, is his wife, Sue Henry, who has been to 78 of his 80 arguments. Phillips thinks she\u2019s gotten 77 right.\n\n\u201cIt\u2019s incredible to me,\u201d he said. \u201cShe\u2019ll come out and say, \u2018You were great, but you\u2019re going to lose.\u2019\u201d\n\nHe\u2019s skeptical of a computer being able to help in oral argument preparation. \u201cI doubt it, because of the format. Realistically, you get about 30 seconds to say something to the justices before they start asking questions,\u201d he said.\n\nBut Phillips can imagine a world where computers could make a difference, if they went beyond simple affirm-or-reverse predictions.\n\n\u201cIf you can come up with a computer that can tell me how the justices are actually going articulate the principle that applies, ahead of time, that I would pay dearly for,\u201d he said, referring to the nuanced interpretation of the law that the justices often hand down in their final rulings. \u201cThat\u2019s, candidly, a huge advance.\u201d\n\nNasrallah rattled off a number of improvements he hopes to make to his model: It doesn\u2019t yet analyze what the advocates say. Its sentiment analysis could be improved (it\u2019s currently trained on a database of movie reviews, which might not be the best analog for the type of language usually used in legal arguments). It could look at specific types of words. Maybe a justice saying a lawyer\u2019s name, for example, is meaningful. Perhaps humor \u2014 statements followed by \u201c(laughter)\u201d in the transcripts \u2014 holds information. The model could read in past decisions, briefs, statutes, and on and on.\n\nThere are other models that CourtCast could team up with, creating a kind of super-algorithm. {Marshall}+, another prominent Supreme Court case predicting model, doesn\u2019t use any information from the oral arguments, and CourtCast, at least so far, doesn\u2019t use any of the legal coding that {Marshall}+ relies on. Because they\u2019re predicting based on mutually exclusive sets of information, they could combine and, theoretically, form a Frankenstein\u2019s monster of high court prediction.\n\nBut not every human welcomes our court-predicting robot overlords.\n\n\u201cThe idea that you spend a lot of time trying to figure out ahead of time what you\u2019re going to know anyway in a matter of weeks or months is, to me, insane. Why would you bother?\u201d Totenberg wondered.\n\nBecause we want to know now, Ms. Totenberg, that\u2019s why! I write for FiveThirtyEight \u2014 we updated our March Madness predictions approximately 17 times while I wrote this sentence. (Editor\u2019s note: Sorry it took me so long to get to your draft, Ollie.) Data promises us our crystal ball, doesn\u2019t it?\n\nBut Totenberg made the case that the court\u2019s decisions can only be understood through the long lens of history. Prediction is a waste of time, she told me. Supreme Court decision-making is complex, and justices\u2019 rubrics can change dramatically over time. Justice Kennedy famously did an about-face in the middle of two major cases, reversing his long-held ideological views and voting to preserve the right to abortion and to ban clergy-led prayer at public schools. And we know only about these last-minute vote changes thanks to the release of Justice Harry Blackmun\u2019s papers in 2004, five years after Blackmun died. What algorithm could\u2019ve predicted that?\n\n\u201cSometimes you only understand these things as history \u2014 and you\u2019re lucky if you understand it as recent history,\u201d Totenberg said.\n\nPut aside whether CourtCast and its ilk are any good (or will become any good) at predicting cases; they\u2019re still a blow against an opaque court.\n\n\u201cThe court is so bound up in its own mystique and gravitas and the need to insulate itself from scrutiny of any sort,\u201d said Lithwick. \u201cIt\u2019s always fascinating to me when \u2014 whatever frame people use \u2014 [people] say, \u2018Oh no, it\u2019s actually not oracular. There\u2019s something else happening.\u2019\u201d\n\nAnd this is what CourtCast has begun to do. If Ginsburg ignores a lawyer, that means something. If Kennedy peppers a lawyer with questions, that means something else. And now we can quantify these things and how they augur for a case\u2019s outcome.\n\n\u201cThese are the kinds of things that make the justices mental \u2014 any intimation that they\u2019re not magic. For me, it\u2019s just delicious,\u201d Lithwick said.\n\nRegardless, most see the court\u2019s frostiness as unlikely to thaw.\n\n\u201cUnless Congress literally threatens to shut [off] the lights and the heat, I don\u2019t think this changes soon. And it\u2019s very, very, in my view, appalling in a democracy,\u201d Lithwick said.\n\nIn the meantime, hobbyists and professionals will continue to probe the court, whether through horse sense or hard analytics. The better the analytics get, the more they\u2019ll be relied upon, and the thinner the shroud will become.", "article_metadata": {"description": "Despite the gleaming white building that houses it, the Supreme Court is one of the most powerful black boxes in the country. When it convenes for oral argument\u2026", "generator": "WordPress.com", "author": "Oliver Roeder", "og": {"site_name": "FiveThirtyEight", "description": "Despite the gleaming white building that houses it, the Supreme Court is one of the most powerful black boxes in the country. When it convenes for oral arguments, there are no photos, no videos, no\u2026", "title": "How To Read The Mind Of A Supreme Court Justice", "url": "http://fivethirtyeight.com/features/how-to-read-the-mind-of-a-supreme-court-justice/", "image": {"width": 575, "identifier": "https://espnfivethirtyeight.files.wordpress.com/2015/04/fivethirtyeight-20150427-thumbnail.jpg", "height": 431}, "locale": "en_US", "type": "article"}, "twitter": {"creator": {"identifier": "ollie", "id": 8593862}, "image": {"src": "https://espnfivethirtyeight.files.wordpress.com/2015/04/fivethirtyeight-20150427-thumbnail.jpg?w=640"}, "maxage": 300, "site": {"identifier": "FiveThirtyEight", "id": 2303751216}, "widgets": {"csp": "on"}, "card": "summary_large_image"}, "msapplication-tooltip": "Nate Silver\u2019s FiveThirtyEight uses statistical analysis \u2014 hard numbers \u2014 to tell compelling stories about politics, sports, science, economics and culture.", "DC.date.issued": "2015-04-28T12:51:02+00:00", "fb": {"app_id": 797620670264818, "pages": 687958677914631}, "msapplication-window": "width=device-width;height=device-height", "msapplication-task": "name=Subscribe;action-uri=http://fivethirtyeight.com/feed/;icon-uri=http://0.gravatar.com/blavatar/cb2459913f2d34a9135edfd3cbae1a15?s=16", "application-name": "FiveThirtyEight", "article": {"publisher": "https://www.facebook.com/FiveThirtyEight", "published_time": "2015-04-28T12:46:33+00:00", "modified_time": "2015-04-28T12:51:02+00:00", "author": "http://fivethirtyeight.com/contributors/oliver-roeder/"}, "google-site-verification": "u4S1gkGQ7IEq1C4S6i3KdYNnPhtuqfsaSIeP0Qqin68", "viewport": "width=device-width, initial-scale=1", "news_keywords": "Algorithms, Dahlia Lithwick, Nina Totenberg, Sonia Sotomayor, Supreme Court"}, "_id": "\"57477af46914bd0286fd9f10\"", "article_summary": "None of CourtCast\u2019s findings came as a surprise to Adam Liptak, the Supreme Court correspondent for The New York Times.\nDespite the gleaming white building that houses it, the Supreme Court is one of the most powerful black boxes in the country.\nHe\u2019s used them to create CourtCast, a computer model that predicts Supreme Court decisions based on oral arguments alone.\nLiptak and Dahlia Lithwick, Slate\u2019s Supreme Court writer, both emphasized the importance of attending oral arguments rather than just parsing transcripts.\nI\u2019ve written before about other Supreme Court predictors \u2014 law professors, legal practitioners, hobbyists in Queens."}