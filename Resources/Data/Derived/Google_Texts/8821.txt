The way we register spoken words may not be purely grammatical — the gender of the talker also impacts how our brains linguistically break down what is said.

A person's gender affects how quickly and accurately a listener is able to grammatically make sense of their words, psychologists report. The finding adds to the debate about whether the nature of the speaker impacts how we process what they say.

For decades, psychologists have debated whether our brains objectively process grammar and syntax. One side argues that words we hear get filtered; the details that are irrelevant to the actual meaning of the word get extracted, leaving just the essence of the word for our brains to store. The other side of this debate takes the view that our brains retain information about both the words and the speaker who uttered them.

“Our study shows that all that other information does influence not just word recognition processing, but higher-level processes associated with grammar,” commented lead author of the study, Michael Vitevitch, in a press release.

In the University of Kansas study, participants were tested on how rapidly and precisely they could distinguish between masculine and feminine words in a list of Spanish words. The grammatical gender of Spanish words are usually defined as masculine when they end in “o” and feminine when they end in “a”. Researchers found that when a participant heard a word that was uttered by someone whose sex was opposite to the gender of the word — a “mismatch” — their ability to grammatically identify the word was slower than when they responded to a "match."

“This result … raises questions regarding the widespread assumption about the cognitive independence and automatic nature of grammatical processes,” the authors concluded in their study. “[A]coustic information associated with the sex of a speaker interacts with the processing of the linguistic information associated with grammatical gender, suggesting that grammatical processing may not be as cognitively distinct from outside sources of information as previously held.”

Commenting on the wider implications of his study regarding the long running debate about whether memory is more abstract or contextual, Vitevitch noted that “we didn’t evolve to be efficient. We evolved to get the job done,” he said. “We need both systems.”

Vitevitch's finding means that when we listen to somebody speak, the information that we glean from the “speech signal” is not purely linguistic. In addition to our brains deciphering the grammatical nuts and bolts of words — their phonology, semantics, and syntax — our memories are also registering their “paralinguistic” aspects, i.e. details about the person delivering the words; their regional and economic background, emotional state, age, and gender.

The study authors pointed out the theoretical importance of the study in terms of understanding cognition, whereby “lower level” acoustic information that corresponds to the identity of the speaker influences the processing of “higher-level” information that is related to linguistics — in this case the grammatical gender of words.

Source: Vitevitch M, Sereno J, Jongman A, et al. Speaker Sex Influences Processing of Grammatical Gender. PLOS One. 2013.