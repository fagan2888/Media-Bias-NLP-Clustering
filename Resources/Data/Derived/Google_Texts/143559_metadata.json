{"article_title": "Hated the Facebook experiment? You'll hate what's next for health care.", "article_keywords": ["information", "whats", "big", "hated", "hate", "data", "experiment", "facebook", "consent", "health", "patient", "millions", "youll", "think", "care"], "article_url": "http://www.vox.com/2014/7/14/5893787/big-data-health-care-glenn-cohen", "article_text": "Facebook isn't the only company that wants to capitalize on information collected from millions of people do do research. Health care systems want to use the immense sea of data in patients' medical records to try and improve health and reduce costs.\n\nFor example, doctors might use patterns in hospital data to determine whether a patient is at high risk of cardiac arrest and should be admitted to the intensive care unit. The data used to make those decisions will be collected from thousands \u2014 or millions \u2014 of hospital visits, raising questions about the security of the data, and whether it's appropriate to use it to make medical decisions for individual patients.\n\nI. Glenn Cohen is a professor of health law and ethics at Harvard Law School. He recently co-authored a paper on the new role that data is starting to play in health, and the legal and ethical wrinkles introduced by using that data to make medical decisions. We discussed some of those problems, and how they might be handled in the future.\n\nWhat follows is a transcript of our conversation, edited for length and clarity.\n\nAdrianna McIntyre: What is \"big data\" in health care, and why this it emerging as a policy issue now?\n\n\"it's now possible to aggregate data from millions and millions of patient experiences\"\n\n\n\nI. Glenn Cohen: There are different definitions, but essentially \"big data\" in health care refers to the idea \u2014 particularly with the shift to electronic health records \u2014 that we have millions and millions of patient records that are now in the process of being digitized, as well as tons of information from genetic samples, tissue samples, and the like. Increasingly, we're able to combine these records for analysis.\n\nIt's now possible to aggregate data from millions and millions of patient experiences, and to use that information to reform our health care system and make individualized patient decisions and do research.\n\nOne way big data is emerging is predictive analytics, which uses an algorithms to analyze data and generate suggestions for the future health of a particular patient \u2014 to decide whether a specific patient should be admitted to the intensive care unit or not, for example.\n\nAM: In the paper, you say that big data in health care seems to exist in this kind of gray area between \"quality improvement,\" which doesn't require explicit consent to use people's data, and \"human subjects research,\" which does. That gray area has gotten a lot of attention recently, with the controversy over Facebook's emotions study. Are there parallels we can draw here?\n\nIGC: I was actually asked about Facebook at the Health Affairs briefing. I'm paraphrasing here, but the question was something like, \"Cohen, aren't you being a little silly to be talking about all of these kinds of entities \u2014 HIPAA, the health privacy law \u2014 when corporations like Walmart and Facebook know an awful lot about us, and they're not governed by any of these laws?\"\n\nWhat I said to the gentleman who asked is that this is an argument for asymmetry. You have A and B \u2014 health care systems and Facebook \u2014 who look very similar in the way the know information about us, and one is heavily regulated and one is not.\n\nThe way you can resolve that kind of argument is in either direction: it either means we should treat health care practitioners of the world more like Facebook \u2014 let them set their own terms of use, no regulation of what's done \u2014 or, we could treat the Facebooks of the world more like health care and apply a whole set of rules about de-identification of data and consent and the like.\n\nThe other possibility is that there are significant differences between the two, such that different regulatory regimes are appropriate. I think I fall somewhere in that middle.\n\n\"In health care, the person you share data with is supposed to have your best interests at heart. Facebook is not the same.\"\n\n\n\nI think the relationship you have with a doctor is a special relationship. You are sharing health information with the view that this person is looking out for your best interests. They're paid, but we have a whole bunch of regulations in place to make sure that health care professionals don't act out of their own interests instead of the interests of their patients. It seems to me that Facebook is not the same kind of relationship, and we've never pretended otherwise.\n\nI do think there is a crucial difference in that part of what we're trying to do in health care is make sure people trust their doctors. Protections exist in health care \u2014 but not for Facebook \u2014 in part because we've established this particular kind of relationship where the person you're sharing your information with is only supposed to have your best interests at heart.\n\nIf you believe that about Facebook, I think you have bigger problems.\n\nAM: So, how do we navigate the consent issue for collection and use of personal data in health care \u2014 and, eventually, the predictive analytics models that could help doctors make treatment decisions?\n\nIGC: The way I think about this is a little bit like a see-saw, where you have consent on the one side and privacy and de-identification on the other side. The more we invade your privacy, the more we need robust consent mechanisms. I think of privacy as your right to stop people from knowing things about you that you don't want them to know \u2014 things that can be tied directly to your identity as an individual.\n\nThe federal system of privacy regulation adopts a similar philosophy: It demarcates 18 identifiers that have to be stripped from health information about a patient before you can transfer data between covered entities. After stripping those identifiers, consent is not necessarily required to use that data for some kinds of research.\n\nTo me, nothing is ever truly de-identified. We've had studies that have taken random genetic samples, and with very little additional information \u2014 like just the zip code \u2014 they've been able to reverse-engineer the identities of research subjects.\n\n\"Nothing is ever truly de-identified \u2014 but 'big data' could make de-identification easier.\"\n\nThat said, it requires a lot of expertise and a lot of money, and we don't think that people will routinely do this. But we think the development of these \"big data\" datasets and algorithms could actually make de-identification easier.\n\nOur ability to de-identify data exists on a continuum. But the closer you get to an acceptable level of de-identification \u2014 where someone would have to do a lot to re-identify you \u2014 the more ethical it seems to me that this proceed without individual consent.\n\nEven then, we suggest that even then, it maybe be paired with other kinds of assurances, like auditing by third-party institutions that we trust, protections like the ones that exist when people have their identities stolen, legal remedies if there is a data breach, and also the kind of naming-and-shaming techniques that have been used against Target and other institutions in the wake of data breaches.\n\n\"THE COSTS OF REAL, MEANINGFUL CONSENT ARE too GREAT.\"\n\nThe bottom line is, if I were to require your explicit consent each and every time I recorded something into your electronic health record, to share it with the database and the algorithms, essentially this technology would not work, because the costs of doing real, meaningful consent are too great.\n\nWhat we think instead would be more reasonable is that when you enter a practice, there should be notification and an informational session \u2014 interactive and ongoing, where it's not just signing a piece of paper, but you are made to understand what it really means to have this information shared in the database, and maybe an opportunity to opt out.\n\nAM: One problem your paper talks about is that these predictive analytics might make patients that are already marginalized by the health care system \u2014 people who are disadvantaged because of illness, lack of access to health care, or poverty\u2014 worse off.\n\nIGC: In order to do \"big data\" properly, you want huge networks of electronic health records to get the data from, and you want to make sure you have a diverse population that reflects the diversity of the United States. We want to get everyone involved in contributing their data.\n\n\"Those who contribute ought to be able to benefit.\"\n\nBut most of the predictive analytics engines that are being developed are being developed by for-profit corporations. Ultimately, those corporations are hoping to sell what they do with these algorithms to individual hospitals or hospital systems.\n\nOne of our concerns is that resource-constrained hospitals \u2014 and patients who go to resource-constrained hospitals \u2014 their data may go toward building the system, but they may not enjoy the benefits of the system because their particular hospital can't afford or chooses not to buy these kinds of technology.\n\nA lot of onus is going to fall on state, local, and federal government to subsidize the acquisition of these kinds of models if they show themselves to be effective in resource-poor settings. But we also think that the developers of these model may have an ethical obligation to adopt graduated licensing, similar to what some pharmaceutical companies have done to improve the availability of drugs in the developing world.\n\nWe think that basically those who contribute to the development of the model ought to be able to benefit from the use of that model. We have a fear that may not happen without these kinds of interventions.\n\nAM: Are there ways that the data could be used more actively to the detriment of high-need patients?\n\nIGC: This kind of big data has the potential to allow insurers or medical providers to develop strategies to avoid high-cost patients. The idea is that, given enough data, I can spot you without using the old-fashioned categories that run into problems, like race, socioeconomic status, age and the like \u2014 law prohibits using that information on anti-discrimination laws. But in the future, I might be able to spot you through sophisticated data-mining.\n\n\"there could be people who want to use the data for purposes that widen health disparities, not solve them.\"\n\nMy take on this is that before the Affordable Care Act, I would have been much more worried about this. After the Affordable Care Act, we have beefed up anti-discrimination rules for insurers and we also have other laws like the Genetic Information Nondiscrimination Act (GINA), which prohibits certain forms of discrimination based on genetic data. So, I think this is a real concern, but recent legislative efforts have made me more comfortable with the notion.\n\nBut it's definitely true that with this system, somebody who wants to use the system will be able to know a lot more about you and the likely future of your health state than they could know now. I imagine even with these legal protections, there could be some entities or people who want to use the data for purposes that will widen health disparities, not solve them.", "article_metadata": {"outbrainsection": "health-care", "description": "What happens when 'big data' meets health care?", "author": "Adrianna McIntyre", "og": {"site_name": "Vox", "description": "What happens when 'big data' meets health care?", "title": "How health care providers might be like Facebook", "url": "http://www.vox.com/2014/7/14/5893787/big-data-health-care-glenn-cohen", "image": "https://cdn0.vox-cdn.com/thumbor/zTvWD6oGGWa9IHqeSbsXENnu7Gs=/0x113:2040x1246/1080x600/cdn0.vox-cdn.com/uploads/chorus_image/image/35528590/151058934.0.jpg", "type": "article"}, "twitter": {"description": "What happens when 'big data' meets health care?", "title": "How health care providers might be like Facebook", "url": "http://www.vox.com/2014/7/14/5893787/big-data-health-care-glenn-cohen", "image": {"src": "https://cdn0.vox-cdn.com/thumbor/zTvWD6oGGWa9IHqeSbsXENnu7Gs=/0x113:2040x1246/1080x600/cdn0.vox-cdn.com/uploads/chorus_image/image/35528590/151058934.0.jpg"}, "site": "voxdotcom", "card": "summary_large_image"}, "sailthru.date": "2014-07-14", "sailthru.title": "Hated the Facebook experiment? You'll hate what's next for health care.", "fb": {"app_id": 1477830955774082}, "bitly-verification": "e91f59418032", "google-site-verification": "xeeKG0aZW_ixnlmi4BiccQuHOAzkssX1wPL70NqdnXw", "sailthru.tags": "general,vox", "article": {"publisher": "https://www.facebook.com/Vox", "published_time": "2014-07-14T13:45:02Z"}, "sailthru.description": "What happens when 'big data' meets health care?", "viewport": "width=device-width, initial-scale=1, user-scalable=yes, shrink-to-fit=no"}, "article_summary": "AM: One problem your paper talks about is that these predictive analytics might make patients that are already marginalized by the health care system \u2014 people who are disadvantaged because of illness, lack of access to health care, or poverty\u2014 worse off.\nAdrianna McIntyre: What is \"big data\" in health care, and why this it emerging as a policy issue now?\nHealth care systems want to use the immense sea of data in patients' medical records to try and improve health and reduce costs.\nYou are sharing health information with the view that this person is looking out for your best interests.\n\"In health care, the person you share data with is supposed to have your best interests at heart."}