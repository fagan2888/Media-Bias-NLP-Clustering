“As a nation, we have to make college more accessible and affordable and ensure that all students graduate with a quality education of real value.”

--Secretary Arne Duncan, December 19, 2014

With the release of the Obama administration’s much-anticipated framework for rating the nation’s colleges and universities, commentators already are weighing in on the yawning gulf between the stated intention of ensuring “a quality education of real value” and the severe limitations of the metrics being considered. While the proposed college ratings system can and should expose some truly bad institutions that don’t deserve to receive federal support, the ratings framework by design presents a severely limited picture of how individual colleges and universities serve students and the nation. Regardless of whether one judges the proposed ratings data to be clarifying or misleading, the fact remains that the most important outcome of higher education — the impact a college or university has on student learning outcomes — is completely missing from the federal ratings framework.

American higher education urgently needs a college learning assessment system, but not one that equates student learning with disciplinary knowledge alone. Rather, it needs a way to account for the higher-order capacities and skills that are the hallmarks of a liberal education. The ordinary citizen will very reasonably assume that the college ratings system the federal government is now poised to promote does provide the needed evidence on college learning and quality. (Secretary Duncan himself seems to assume this, as the quote above makes clear.)

But the ordinary citizen will be wrong in this assumption. The proposed college ratings system does not, in fact, provide any evidence at all about the quality of student learning. By design, the federal ratings system is focused carefully and exclusively on data related to who enrolls in college, institutional affordability, and employment at a living wage after graduation.

What then should we do about the quality of learning challenge? What America absolutely does not need the federal government to do — and what the administration has so far very prudently and thoughtfully refrained from doing — is to create a national, federally devised and controlled system that would specify what the learning goals of college should be and then assess whether students are achieving them. Nonetheless, the public does need to know how well colleges, universities, and community colleges are doing in providing the kinds of learning that contribute directly to students’ success beyond graduation.

Under established law, private college and university boards of trustees and public college and university state system governing arrangements rightly determine the missions of individual higher education institutions, and through longstanding shared governance arrangements faculty and institutional leaders set the goals for student learning on individual campuses with the needs and goals of students and of the nation very much in mind. Yet there is wide recognition — especially among America’s employers, but also within higher education itself — that far too few students graduate from college well-enough prepared for success in work, civic participation and democratic citizenship, and life in the 21st century.

American higher education must do much better in both assessing and improving learning.

And, on this front, there is genuinely good news to report. This year, far away from the ratings furor, educators themselves are taking the lead in developing the kind of learning assessments the public deserves from higher education. The VALUE (Valid Assessment of Learning in Undergraduate Education) initiative of the Association of American Colleges and Universities (AAC&U) represents an important step forward — one that has at its core not only the assessment of student learning, but also the creation of a platform for providing institutions with direct feedback to support continuous quality improvement in teaching and learning. Developed in 2007 through a national collaboration of faculty, institutional, and state-system leaders along with content knowledge and student learning experts, the VALUE approach to assessment has since gained acceptance with remarkable speed.

This year, building on this foundation, AAC&U, the State Higher Education Executive Officers Association (SHEEO), nine state systems, and 85 public and private institutions are engaged in a major proof of concept study designed to demonstrate the different direction the VALUE approach represents both for assessing learning outcomes and for providing useful feedback to educators about strengths and needed improvements in student performance. The states working in concert with AAC&U and SHEEO are Connecticut, Indiana, Kentucky, Massachusetts, Minnesota, Missouri, Oregon, Rhode Island, and Utah. Private liberal arts institutions in additional states also are contributing to the study.

Under the VALUE approach, rubrics — common across participating institutions — are used rather than standardized tests, and scores are based on faculty judgments about actual student work. Specifically, graded student work products that show what a student knows and can do — an essay, a piece of creative writing, a lab report, an oral presentation — are evaluated and scored by faculty members (not those who originally assigned and graded the work product) against a rubric that describes multiple dimensions of what it means to do critical thinking, quantitative reasoning, integrative reasoning, or any of the other forms of higher-order learning for which the VALUE rubrics describe achievement at different levels. The exciting promise of this work is that higher education itself is advancing an approach to assessment that is meaningful and accessible to faculty, students, and higher education stakeholders alike.

The VALUE rubrics were initially created by faculty members, and they reflect educators’ shared judgments about both the substance and the quality of student learning outcomes. Teams of faculty and academic professionals from more than 100 campuses across the country contributed to the development of these VALUE assessment rubrics for each of 16 liberal learning outcomes: inquiry and analysis, critical thinking, writing, integrative learning, oral communication, information literacy, problem solving, teamwork, intercultural knowledge, civic engagement, creative thinking, quantitative literacy, lifelong learning, ethical reasoning, global learning, and reading. These outcomes are important to the education of all college students, whether in two-year or four-year institutions, liberal arts or pre-professional programs, online or in-person courses, and regardless of institutional mission.

But the VALUE approach offers more than just a way to assess student learning. It is itself potentially a “high-impact practice” that will lead to greater student persistence and completion and to a reduction in the achievement gap between white students and disadvantaged students of color. The VALUE rubrics show students what excellence with regard to a particular learning goal looks like, and they let students see where they are on the path toward excellent performance. When faculty talk with students about their work and how it was scored, they are providing students with precisely the kind of “frequent, timely and constructive feedback,” “interactions with faculty ... about substantive matters,” and “structured opportunities to reflect on and integrate learning” that is characteristic of high-impact practices as George Kuh has defined them in his influential reports. In addition, AAC&U has learned already from campuses piloting the use of VALUE rubrics that, after initial experiences with the rubrics, faculty come together to develop assignments that directly address higher-order liberal learning skills — especially evidence-based reasoning — rather than lower-order skills such as description, summary, and paraphrase. None of this happens when a student is sent his or her score on a standardized test. This feature of VALUE, above and beyond its great utility as an assessment system, is responsible for its already very wide and growing support in colleges, universities, and state systems nationally.

What the federal government could and should do, even as it develops and tests its new ratings system, is to remind the nation, over and over, that student acquisition of the knowledge and skills college graduates need is the primary and most critical public purpose for which colleges and universities are chartered. Hence, the federal government should say that assessing what college students know and can do must be a very high institutional — and, for public institutions, institutional and state-system — priority.

While the federal government should not seek to take responsibility for this assessment, it can and should remind those properly responsible that the quality and assessment of student learning — not just access, completion, and non-learning outcomes — must become a top priority.

At the very least, the US Department of Education should publicly be calling attention to and rooting for the success of state- and institution-driven efforts like VALUE that have national potential. But it also could, through existing federal grant programs such as the Fund for the Improvement of Postsecondary Education (FIPSE) or through Department of Education contracts, create incentives for institutions and state systems to adopt new assessment approaches by offsetting temporary institutional “ramping-up” costs or providing financial support for the necessary infrastructure to allow initiatives like VALUE to become functional nationwide.

This is how public-private partnerships should work: investing in promising ideas and facilitating their testing as they develop. Both at the federal and state levels, public policy can be an enabler for the radically better approach to assessment that VALUE represents.

So even as we debate what’s right or wrong with the ratings, let’s remember that advancing accountability in higher education ultimately needs to include what students are learning.