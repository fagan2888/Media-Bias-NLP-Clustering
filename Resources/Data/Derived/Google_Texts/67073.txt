The Affordable Care Act’s website debut has been compared to the Titanic disaster. The analogy is fair, in that the ship’s captain demonstrated an inexplicable lack of interest in and respect for the risks presented by the iceberg-infested waters through which his vessel was sailing.

Whatever warnings there were reached him too late: It is virtually impossible to change quickly the course of a massive technological system after an equally massive obstacle is spotted in its path. Given the design of the ship, once it took on more and more water, there was little hope for saving it.

As many parallels as there are between the fateful maiden voyage of the Titanic and the launch of Healthcare.gov, however, there is another colossal technological disaster that may be even more apt: the catastrophic 1986 explosion of the space shuttle Challenger just 73 seconds after liftoff.

Exhaustive postaccident analyses revealed that the immediate cause of the failure was technical: an O-ring that could not sustain the pressures of the launch. However, the underlying cause of the Challenger disaster was not in the engineering so much as in the management and operation of the shuttle program. On the eve of the launch, engineers warned temperatures were too cold for them to have confidence that success could be achieved.

To launch in such weather was to gamble in a gray area between risk and wisdom. The managers, however, overruled the engineers. The Challenger launch, like that of the Affordable Care Act website, took place nonetheless, and the rest is history.

It was widely believed that the reason the NASA managers were so reluctant to listen to the engineers was that postponing the launch would be embarrassing to the White House, which had plans to tie into President Ronald Reagan’s State of the Union address the presence of a teacher in the orbiting shuttle.

The post-accident reporting on the Challenger disaster focused a good deal on the technology, especially on the notorious booster rocket joints sealed by O-rings that failed in cold weather.

But underlying all the technology was the action, interaction and inaction of people within the organization. The term “organizational culture” came to be used with the adjective “deviant” to describe an inordinate tolerance for hubris and risk that had developed within the agency.

There is certainly enough circumstantial evidence that a deviant organizational culture has taken hold within the White House today. If there was any communication between the computer scientists and engineers who worked on the health care website and the administration, it appears to have been largely one-way and grossly ineffective.

If there is to be an in-depth “accident investigation” of the decision to launch the website when it was activated, one can only hope that the inquiry will not focus primarily on the millions of lines of computer code.

What will be far more important to understand and address is not what lines of code are to blame but what lines of communication were — and probably remain — faulty. (Recall that much of NASA’s deviant organizational culture remained in place at the time of the shuttle Columbia accident, 17 years after Challenger exploded.)

Large technological systems such as those for the Titanic and Challenger are more than engineering; their design and operation are embedded in human spheres of influence — many with more sway than technological savvy and good judgment.

Those who wield sheer political power may come to believe that they can by force of will ignore the laws of large numbers and the odds of engineering risk, but they do so at their own and the country’s peril. Letting political calendars have too much influence on technological decisions is bad politics, bad management and bad technology.

Petroski is a professor of engineering and of history at Duke. His latest book is “To Forgive Design: Understanding Failure.”