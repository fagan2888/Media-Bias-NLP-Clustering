Cardiologists recently hailed early results of a study suggesting that many lives might be saved if people with high blood pressure got it down far below levels now recommended. They predicted swift changes in treatment practices. Patients rushed to call their doctors.

But the intense interest in this big, rigorous clinical trial masked a startling truth about heart research: Many studies are never published at all, their findings consigned to oblivion.

It is an issue that is arising in other parts of medicine as well, but heart disease is one area where it has been especially well documented. Hundreds of millions of dollars have been going to heart studies that are too small and narrow to yield results meaningful enough to get into a journal. In an era of ever-tightening budgets, federal health officials acknowledge that money has been squandered on work that makes no difference to patients or even to research scientists.

Now, a few years after coming to that jolting realization, the influential federal agency that funds much of the nation’s heart research is overhauling its practice, a change with far-reaching implications for the way medical research is funded in this country. The result will be the financing of fewer, but deeper, studies, to focus resources on efforts with real-world impact and life-or-death implications.

“We are much more willing to turn down proposed trials,” said Dr. Michael Lauer, a cardiologist who is the newly appointed deputy director for extramural research of that agency, the National Institutes of Health. In fact, he added, “we are turning them down.”

The pronounced shift is shaking up a field where change is usually measured in tiny increments. Some question this new direction.

“If you want to do things that are truly innovative and cutting-edge, you sometimes have to do things that are high risk-high gain,” said Dr. Steven A. Webber, a pediatric cardiologist at Vanderbilt, arguing for the need to continue funding small exploratory studies like one he conducted, which he could not complete because of unexpected technical issues.

This rethinking of how to study heart disease, which kills more than 600,000 Americans a year, began with an epiphany three years ago: Lauer and colleagues at the National Heart, Lung and Blood Institute discovered they had spent $2 billion on more than 200 clinical trials over the course of a decade. But the results of 2 out of 5 of the studies were either never made public or were published only after what to scientists were unconscionable delays.

“If a research project is never published, it is as if it never happened,” Lauer said.

So starting next year, the heart institute will require that all research results be reported in a federal database even if no journal will publish them. In addition to turning down smaller studies, it is insisting that the costs of large studies go way down — even if that means sacrificing data by, for example, not gathering lab results on peripheral questions researchers think are interesting.

Though some researchers are unsettled by the new practices, many agree that money was often wasted under the old system. Five small studies cost less than one large one, so the temptation, federal officials acknowledge, has been to stuff the clinical trials portfolio with small studies, especially given the reality of the federal budget. Funds for the NIH have fallen by 20 percent in inflation-adjusted dollars since 2006.

“It’s worth understanding how perverse — and that’s the right word — the environment has been for clinical trials,” said Dr. Salim Yusuf, a cardiologist at McMaster University in Ontario.

Lauer never expected to uncover such a troubled system when he asked for data on the publication — or nonpublication — of heart institute studies. The results shocked him and his colleagues, and after some soul searching they reported their findings in The New England Journal of Medicine. They realized they were airing what some said was the institute’s dirty laundry in a journal that is all but required reading for medical researchers.

“We did it anyway,” Lauer said, explaining that he could hardly criticize others for not publishing and then fail to publish his own results.

Lauer’s study found that trials of treatments with an obvious life-or-death meaning for patients, like testing a way to cut heart attacks, almost always were published within two years of completion; 70 percent were published a year or less after the trial closed. Negative or equivocal results did not make any difference in publication rates.

But trials with so-called surrogate endpoints — Did cholesterol levels rise or fall? Did people walk more each day? — tended to languish.

“If you subject a person to the risks and hassles of being in a clinical trial, there is an implicit promise that they are giving to science,” Lauer said. “Giving to science means the results get published.”