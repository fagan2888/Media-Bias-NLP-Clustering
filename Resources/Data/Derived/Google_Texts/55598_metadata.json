{"article_title": "Privacy not included: Federal law lags far behind new tech", "article_keywords": ["information", "paternity", "privacy", "far", "data", "lags", "federal", "test", "tech", "online", "included", "health", "law", "technology", "users"], "article_url": "http://www.salon.com/2015/11/21/privacy_not_included_federal_law_lags_behind_new_tech_partner/", "article_text": "Topics: NSA, Paternity Test, ProPublica, technology, Washington Post, Innovation News, Technology News\n\nThis originally appeared on ProPublica\n\nThis story was co-published with the Washington Post.\n\nJacqueline Stokes spotted the home paternity test at her local drugstore in Florida and knew she had to try it. She had no doubts for her own family, but as a cybersecurity consultant with an interest in genetics, she couldn\u2019t resist the latest advance.\n\nAt home, she carefully followed the instructions, swabbing inside the mouths of her husband and her daughter, placing the samples in the pouch provided and mailing them to a lab.\n\nDays later, Stokes went online to get the results. Part of the lab\u2019s website address caught her attention, and her professional instincts kicked in. By tweaking the URL slightly, a sprawling directory appeared that gave her access to the test results of some 6,000 other people.\n\nThe site was taken down after Stokescomplained on Twitter. But when she contacted the Department of Health and Human Services about the seemingly obvious violation of patient privacy, she got a surprising response: Officials couldn\u2019t do anything about the breach.\n\nThe Health Insurance Portability and Accountability Act, a landmark 1996 patient-privacy law, only covers patient information kept by health providers, insurers and data clearinghouses, as well as their business partners. At-home paternity tests fall outside the law\u2019s purview. For that matter, so do wearables like Fitbit that measure steps and sleep, testing companies like 23andMe, and online repositories where individuals can store their health records.\n\nIn several instances, the privacy of people using these newer services has been compromised, causing embarrassment or legal repercussions.\n\nIn 2011, for instance, an Australian company failed to properly secure details of hundreds of paternity and drug tests, making them accessible through a Google search. The company said that it quickly fixed the problem.\n\nThat same year, some users of the Fitbit tracker found that data they entered in their online profiles about their sexual activity and its intensity \u2014 to help calculate calories burned \u2014 was accessible to anyone. Fitbit quickly hid the information.\n\nAnd last year, a publicly accessible genealogy database was used by police to look for possible suspects in a 1996 Idaho murder. After finding a \u201cvery good match\u201d with the DNA of semen found at the crime scene, police obtained a search warrant to get the person\u2019s name. After investigating further, authorities got another warrant ordering the man\u2019s son to provide a DNA sample, which cleared him of involvement.\n\nThe incident spooked genealogy aficionados; AncestryDNA, which ran the online database, pulled it this spring.\n\n\u201cWhen you publicly make available your genetic information, you essentially are signing a waiver to your past and future medical records,\u201d said Erin Murphy, a professor at New York University School of Law.\n\nThe true extent of the problem is unclear because many companies don\u2019t know when the health information they store has been accessed inappropriately, experts say. A range of potentially sensitive data is at risk, including medical diagnoses, disease markers in a person\u2019s genes and children\u2019s paternity.\n\nWhat is known is that the Office for Civil Rights, the HHS agency that enforces HIPAA, hasn\u2019t taken action on 60 percent of the complaints it has received because they were filed too late or withdrawn or because the agency lacked authority over the entity that\u2019s accused. The latter accounts for a growing proportion of complaints, an OCR spokeswoman said.\n\nA 2009 law called on HHS to work with the Federal Trade Commission \u2014 which targets unfair business practices and identity theft \u2014 and to submit recommendations to Congress within a year on how to deal with entities handling health information that falls outside of HIPAA. Six years later, however, no recommendations have been issued.\n\nThe report is in \u201cthe final legs of being completed,\u201d said Lucia Savage, chief privacy officer of the HHS Office of the National Coordinator for Health Information Technology.\n\nNone of this was useful to the 30-year-old Stokes, a principal consultant at the cybersecurity firm Mandiant. Four months after she filed her complaint with OCR, it suggested she contact the FTC. At that point, she gave up.\n\n\u201cIt just kind of seems like a Wild West right now,\u201d she said.\n\nProtection of Consumer-app Data Varies\n\nAdvances in technology offer patients ways to monitor their own health that were impossible until recently: Internet-connected scales to track their weight; electrodes attached to their iPhones to monitor heart rhythms; virtual file cabinets to store their medical records.\n\n\u201cConsumer-generated health information is proliferating,\u201d FTC Commissioner Julie Brill said at a forum last year. But many users don\u2019t realize that much of it is stored \u201coutside of the HIPAA silo.\u201d\n\nHIPAA seeks to facilitate the flow of electronic health information, while ensuring that privacy and security are protected along the way. It only applies to health providers that transmit information electronically; a 2009 law added business partners that handle health information on behalf of these entities. Violators can face fines and even prison time.\n\n\u201cIf you were trying to draft a privacy law from scratch, this is not the way you would do it,\u201d said Adam Greene, a former OCR official who\u2019s now a private-sector lawyer in Washington.\n\nIn 2013, the Privacy Rights Clearinghouse studied 43 free and paid health and fitness apps. The group found that some did not provide a link to a privacy policy and that many with a policy did not accurately describe how the apps transmitted information. For instance, many apps connected to third-party websites without users\u2019 knowledge and sent data in unencrypted ways that potentially exposed personal information.\n\n\u201cConsumers should not assume any of their data is private in the mobile app environment\u2014even health data that they consider sensitive,\u201d the group said.\n\nConsider a woman who is wearing a fetal monitor under her clothes that sends alerts to her phone. The device \u201ctalks\u201d to her smartphone via wireless Bluetooth technology, and its presence on a network could be detected by others, alerting them to the fact that she\u2019s pregnant or that she may have concerns about her baby\u2019s health.", "article_metadata": {"description": "A leaked paternity test in Florida reveals just how wide the chasm has grown -- and how vulnerable we've become", "title": "Privacy not included: Federal law lags far behind new tech", "og": {"site_name": "Salon", "description": "A leaked paternity test in Florida reveals just how wide the chasm has grown -- and how vulnerable we've become", "title": "Privacy not included: Federal law lags far behind new tech", "url": "http://www.salon.com/2015/11/21/privacy_not_included_federal_law_lags_behind_new_tech_partner/", "image": "http://media.salon.com/2015/11/shutterstock_175661042.jpg", "type": "article"}, "twitter": {"description": "A leaked paternity test in Florida reveals just how wide the chasm has grown -- and how vulnerable we've become", "title": "Privacy not included: Federal law lags far behind new tech", "image": "http://media.salon.com/2015/11/shutterstock_175661042.jpg", "creator": "@salon", "site": "@salon", "card": "summary_large_image"}, "author": "Charles Ornstein", "apple-itunes-app": "app-id=549374205, app-argument=http://www.salon.com/", "fb": {"pages": 120680396518, "app_id": 456294607741273}, "keywords": "Salon.com, NSA, Paternity Test, ProPublica, technology, Washington Post", "viewport": "width=device-width, initial-scale=1.0"}, "article_summary": "Jacqueline Stokes spotted the home paternity test at her local drugstore in Florida and knew she had to try it.\n\u201cConsumers should not assume any of their data is private in the mobile app environment\u2014even health data that they consider sensitive,\u201d the group said.\nTopics: NSA, Paternity Test, ProPublica, technology, Washington Post, Innovation News, Technology NewsThis originally appeared on ProPublicaThis story was co-published with the Washington Post.\nIt only applies to health providers that transmit information electronically; a 2009 law added business partners that handle health information on behalf of these entities.\n\u201cConsumer-generated health information is proliferating,\u201d FTC Commissioner Julie Brill said at a forum last year."}