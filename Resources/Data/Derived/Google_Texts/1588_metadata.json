{"article_title": "Using Algorithms to Hire More Diverse Employees", "article_keywords": ["hire", "diversity", "employees", "infors", "hires", "hiring", "biases", "diverse", "algorithms", "workplace", "using", "data", "candidates"], "article_url": "http://www.theatlantic.com/business/archive/2015/06/algorithm-hiring-diversity-HR/396374/", "article_text": "Now, one company is reporting that algorithmic hiring can also improve diversity. Infor Talent Science provides software that helps companies hire by collecting behavioral information using a survey, then making a predictive model based on top performers. They then hire based on how candidates match up with those top performers. The company dug into data on 50,000 hires for their clients and found an average increase of 26 percent in African Americans and Hispanics hires across a variety of industries and jobs after deploying Infor\u2019s software.\n\nAlgorithmic hiring has been on the rise in recent years. Google used an algorithm to staff up quickly, employing an elaborate survey to zone in on candidates who will fit into the company\u2019s culture. One study of algorithmic hiring found that a simple equation was significantly better than humans at identifying high-performing employees. The result held across different industries and levels of employment, and the researchers attributed the result to humans paying too much attention to inconsequential details and using information about candidates inconsistently.\n\nOne proposed solution is to try to remove some of those biases with systematic analysis of data\u2014or in other words: Use an algorithm. Companies administer personality tests to candidates during screening, then use data analysis to determine its ideal hires. While the algorithm depends on what a company is looking for, common variables include using the data from personality tests to predict whether a candidate will quit or steal on the job .\n\nHumans are biased decision makers. One well-known and troubling example of this is the tendency for interviewers to hire candidates who remind them of themselves , resulting in workplace homogeneity. In the tech sector, this homogeneity has been particularly extreme: Google\u2019s first ever diversity report , released last year, reported only 2 percent of its staff are black, and 3 percent Hispanic, for example. Facebook recently announced that it\u2019s going to try the NFL\u2019s \u201cRooney Rule\u201d \u2014which requires that NFL teams interview minority candidates for coaching positions\u2014in order to expand its staff beyond white and Asian men.\n\n\u201cWhat we've found is regardless of [the industry], whether it's restaurants, retail, call centers\u2014it actually increases the diversity of the population,\u201d says Jason Taylor, Infor\u2019s chief scientist for human capital management. In Infor\u2019s forthcoming report, they found that using an algorithm to help with hiring increased their wholesale clients\u2019 Hispanic hires by 31 percent. For their restaurant clients, African American hires increased by 60 percent.\n\n\u201cWhat a systematic process does is it knows no color, no race, no ethnicity,\u201d says Taylor. \u201cWhen [a hiring manager] doesn't know a person and they don't know what to look for, they basically hire people like themselves. It's \u2018We have something in common,\u2019 or \u2018Oh, I like you,\u2019 then it's \u2018Okay you're hired.\u2019 What this does is it provides them with an objective piece of information that shows the probability that they're going to be successful in the role. So it helps to qualify that pool.\u201d\n\nOne of the caveats of Infor\u2019s study is that their data is only based on hires who disclosed ethnic background. As with most surveys, checking the racial box is voluntary. Collecting racial data has long been tricky as candidates often worry that that it will result in discrimination. (The Census Bureau too suffers from this problem, and it is experimenting with new ways to collecting data about race and origin.) But it\u2019s not clear that, in the end, minority candidates are undercounted: Others might believe that disclosing race will attract diversity-minded employers.\n\nSo will algorithms rid the hiring process of bias? Scholars warn that big data\u2019s supposed objectivity can mask other biases built into the algorithms. Chelsea Barabas, a researcher at MIT\u2019s Center for Civic Media, writes:\n\nDecisions based on algorithms, are becoming \u201cused for everything from predicting behavior to denying opportunity\u201d in a way that \u201ccan mask prejudices while maintaining a patina of scientific objectivity.\u201d These concerns are echoed by other scholars such as Kate Crawford, who has made incisive arguments against the claim that big data doesn\u2019t discriminate against social groups ... The peril of these algorithms is that they mask deep seated biases behind the promise that the numbers \u201cspeak for themselves.\u201d\n\nThere\u2019s plenty of research on the reasons that diversity is good for the workplace: It increases productivity; it enhances problem solving; it\u2019s even been shown to increase sales and improve profits. The question of whether workplace diversity is good seems to have been answered, but the question of how to attain such diversity seems to be the more baffling one.\n\nAt least the early results seem to indicate that algorithmic hiring can help reduce biases, but an employer has to care about doing so. In other words, though Infor\u2019s results are encouraging, what matters most is that companies are genuinely interested in increasing diversity in the workplace.", "article_metadata": {"description": "Some recruiters are hoping that software can somehow compensate for human failings.", "author": "Bourree Lam", "og": {"site_name": "The Atlantic", "description": "Some recruiters are hoping that software can somehow compensate for human failings.", "title": "Can Hiring Algorithms Make Companies More Racially Diverse?", "locale": "en_US", "image": "https://cdn.theatlantic.com/assets/media/img/mt/2015/06/image032/lead_large.jpg", "url": "http://www.theatlantic.com/business/archive/2015/06/algorithm-hiring-diversity-HR/396374/", "type": "article"}, "twitter": {"domain": "theatlantic.com", "site": "@theatlantic", "card": "summary"}, "ROBOTS": "INDEX, FOLLOW", "p": {"domain_verify": "68e1a0361a557708fefc992f3309ed70"}, "fb": {"admins": "577048155,17301937", "page_id": 29259828486, "app_id": 100770816677686}, "keywords": "The Atlantic, The Atlantic Magazine, TheAtlantic.com, Atlantic, news, opinion, breaking news, analysis, commentary, business, politics, culture, international, science, technology, national and life", "viewport": "initial-scale=1.0, maximum-scale=1.0, width=device-width, user-scalable=no"}, "article_summary": "One well-known and troubling example of this is the tendency for interviewers to hire candidates who remind them of themselves , resulting in workplace homogeneity.\nThe question of whether workplace diversity is good seems to have been answered, but the question of how to attain such diversity seems to be the more baffling one.\nInfor Talent Science provides software that helps companies hire by collecting behavioral information using a survey, then making a predictive model based on top performers.\nOne study of algorithmic hiring found that a simple equation was significantly better than humans at identifying high-performing employees.\nIn Infor\u2019s forthcoming report, they found that using an algorithm to help with hiring increased their wholesale clients\u2019 Hispanic hires by 31 percent."}