{"article_title": "Virtual interviewers might offer an advantage to a doctor's questioning", "article_keywords": ["information", "patient", "help", "advantage", "offer", "study", "ellie", "virtual", "interviewers", "patients", "health", "doctors", "questioning", "care"], "article_url": "http://health.heraldtribune.com/2015/08/11/virtual-interviewers-might-offer-an-advantage-to-a-doctors-questioning/", "article_text": "By Suzanne Allard Levingston\n\n\n\nWith her hair pulled back and her casual office attire, Ellie is a comforting presence. She\u2019s trained to put patients at ease as she conducts mental health interviews with total confidentiality.\n\nShe draws you into conversation: \u201cSo how are you doing today?\u201d \u201cWhen was the last time you felt really happy?\u201d She notices if you look away or fidget or pause, and she follows up with a nod of encouragement or a question: \u201cCan you tell me more about that?\u201d\n\nNot bad for an interviewer who\u2019s not human.\n\nEllie is a virtual human created by scientists at the University of Southern California to help patients feel comfortable talking about themselves so they\u2019ll be honest with their doctors.\n\nShe was born of two lines of findings: that anonymity can help people be more truthful and that rapport with a trained caregiver fosters deep disclosure.\n\nIn some cases, research has shown, the less human involvement, the better. In a 2014 study of 239 people, participants who were told that Ellie was operating automatically as opposed to being controlled by a person nearby, said they felt less fearful about self-disclosure, better able to express sadness and more willing to disclose.\n\nGetting a patient\u2019s full story is crucial in medicine. Many technological tools are being used to help with this quest: virtual humans such as Ellie, electronic health records, secure email, computer databases. Although these technologies often smooth the way, they sometimes create hurdles.\n\nHonesty with doctors is a bedrock of proper care. If we hedge in answering their questions, we\u2019re hampering their ability to help keep us well.\n\nBut some people resist divulging their secrets. In a 2009 national opinion survey conducted by GE, the Cleveland Clinic and Ochsner Health System, 28 percent of patients said they \u201csometimes lie to their health care professional or omit facts about their health.\u201d The survey was conducted by telephone with 2,000 patients.\n\nThe Hippocratic Oath imposes a code of confidentiality on doctors: \u201cI will respect the privacy of my patients, for their problems are not disclosed to me that the world may know.\u201d\n\nNonetheless, patients may not share sensitive, potentially stigmatizing health information on topics such as drug and alcohol abuse, mental health problems and reproductive and sexual history. Patients also might fib about less-fraught issues such as following doctor\u2019s orders or sticking to a diet and exercise plan.\n\nREASONS TO DECEIVE\n\nWhy patients don\u2019t tell the full truth is complicated. Some want to disclose only information that makes the doctor view them positively. Others fear being judged.\n\n\u201cWe never say everything that we\u2019re thinking and everything that we know to another human being, for a lot of different reasons,\u201d says William Tierney, president and chief executive of the Regenstrief Institute, which studies how to improve health-care systems and is associated with the Indiana University School of Medicine.\n\nIn his work as an internist at an Indianapolis hospital, Tierney has encountered many situations in which patients aren\u2019t honest. Sometimes they say they took their blood pressure medications even though it\u2019s clear that they haven\u2019t; they may be embarrassed because they can\u2019t pay for the medications or may dislike the medication but don\u2019t want to offend the doctor. Other patients ask for extra pain medicine without admitting that they illegally share or sell the drug.\n\nIncomplete or incorrect information can cause problems. A patient who lies about taking his blood pressure medication, for example, may end up being prescribed a higher dose, which could send the patient into shock, Tierney said.\n\nLeah Wolfe, a primary care physician who trains students, residents and faculty at the Johns Hopkins School of Medicine in Baltimore, said that doctors need to help patients understand why questions are being asked. It helps to normalize sensitive questions by explaining, for example, why all patients are asked about their sexual history.\n\n\u201cI\u2019m a firm believer that 95 percent of diagnosis is history,\u201d she said. \u201cThe physician has a lot of responsibility here in helping people understand why they\u2019re asking the questions that they\u2019re asking.\u201d\n\nTechnology, which can improve health care, can also have unintended consequences in doctor-patient rapport. In a recent study of 4,700 patients in the Journal of the American Medical Informatics Association, 13 percent of patients said they had kept information from a doctor because of concerns about privacy and security, and this withholding was more likely among patients whose doctors used electronic health records than those who used paper charts.\n\n\u201cIt was surprising that it would actually have a negative consequence for that doctor-patient interaction,\u201d said lead author Celeste Campos-Castillo of the University of Wisconsin at Milwaukee. Campos-Castillo suggests that doctors talk to their patients about their computerized-record systems and the security measures that protect those systems.\n\nWhen given a choice, some patients would use technology to withhold information from providers.\n\nRegenstrief Institute researchers gave 105 patients the option to control access to their electronic health records, broken down into who could see the record and what kind of information they chose to share. Nearly half chose to place some limits on access to their health records in a six-month study published in the Journal of General Internal Medicine.\n\nWhile patient control can empower, it can also obstruct. Tierney, who was not involved as a provider in that study, said that if he had a patient who would not allow him full access to health information, he would help the patient find another physician because he would feel unable to provide the best and safest care possible.\n\n\u201cHamstringing my ability to provide such care is unacceptable to me,\u201d he wrote in a companion article to the study.\n\nTHE IMPERSONAL TOUCH\n\nTechnology can also help patients feel comfortable sharing private information.\n\nA study conducted by the Veterans Health Administration found that some patients used secure e-mail messaging with their providers to address sensitive topics \u2014 such as erectile dysfunction and sexually transmitted diseases \u2014 a fact that they had not acknowledged in face-to-face interviews with the research team.\n\n\u201cNobody wants to be judged,\u201d said Jolie Haun, lead author of the 2014 study and a researcher at the Center of Innovation on Disability and Rehabilitation Research at the James A. Haley VA Hospital in Tampa. \u201cWe realized that this electronic form of communication created this somewhat removed, confidential, secure, safe space for individuals to bring up these topics with their provider, while avoiding those social issues around shame and embarrassment and discomfort in general.\u201d\n\nUSC\u2019s Ellie shows promise as a mental health screening tool. With a microphone, webcam and an infrared camera device that tracks a person\u2019s body posture and movements, Ellie can process such cues as tone of voice or change in gaze and react with a nod, encouragement or question. But the technology can neither understand deeply what the person is saying nor offer therapeutic support.\n\n\u201cSome people make the mistake when they see Ellie \u2014 they assume she\u2019s a therapist and that\u2019s absolutely not the case,\u201d says Jonathan Gratch, director for virtual human research at USC\u2019s Institute for Creative Technologies.\n\nThe anonymity and rapport created by virtual humans factor into an unpublished USC study of screenings for post-traumatic stress disorder. Members of a National Guard unit were interviewed by a virtual human before and after a year of service in Afghanistan. Talking to the animated character elicited more reports of PTSD symptoms than completing a computerized form did.\n\nOne of the challenges for doctors is when a new patient seeks a prescription for a controlled substance. Here, technology is a powerful lever for honesty. When her patients request narcotics, Wolfe explains that it\u2019s her office\u2019s practice to check all such requests against a database that monitors where and when a patient filled a prescription for a controlled substance. This technology- based information helps foster honest give-and-take.\n\n\u201cYou\u2019ve created a transparent environment where they are going to be motivated to tell you the truth because they don\u2019t want to get caught in a lie,\u201d she said. \u201cAnd that totally changes the dynamics.\u201d\n\nIt is yet to be seen how technology will evolve to help patients share or withhold their secrets. But what will not change is a doctor\u2019s need for full, open communication with patients.\n\n\u201cIt has to be personal,\u201d Tierney says. \u201cI have to get to know that patient deeply if I want to understand what\u2019s the right decision for them.\u201d", "article_metadata": {"og": {"image": "http://health.heraldtribune.com/files/2015/08/1003235395-fl_sar_hfvirtual.jpg"}, "wp-parsely_version": "1.8", "fb": {"app_id": 846021808821787}}, "_id": "\"57477af36914bd0286fd1aff\"", "article_summary": "\u201cAnd that totally changes the dynamics.\u201dIt is yet to be seen how technology will evolve to help patients share or withhold their secrets.\nEllie is a virtual human created by scientists at the University of Southern California to help patients feel comfortable talking about themselves so they\u2019ll be honest with their doctors.\nMany technological tools are being used to help with this quest: virtual humans such as Ellie, electronic health records, secure email, computer databases.\nPatients also might fib about less-fraught issues such as following doctor\u2019s orders or sticking to a diet and exercise plan.\nTHE IMPERSONAL TOUCHTechnology can also help patients feel comfortable sharing private information."}