{"article_title": "Is Facebook Ruining Democracy?", "article_keywords": ["democracy", "links", "study", "social", "share", "content", "facebook", "ruining", "ideological", "shared", "friends", "users"], "article_url": "http://www.thefiscaltimes.com/2015/05/07/Facebook-Ruining-Democracy", "article_text": "Fox News and other television and online outlets long ago proved the appeal of confirmation bias \u2014 the idea that audiences like to hear what they already believe. But a new study in the journal Science shows that the same holds true on social media, where more and more people are finding their news and increasing personalization driven by algorithms might, in theory, threaten to close people off from ideas that compete with their own.\n\nResearchers at Facebook and the University of Michigan looked at how three different factors affect the ideological diversity of the stories users see and click on in their Facebook feeds. \u201cThe media that individuals consume on Facebook depends not only on what their friends share, but also on how the News Feed ranking algorithm sorts these articles, and what individuals choose to read,\u201d their study explains.\n\nRelated: What Facebook's Zuckerberg Does During His 60-Hour Workweek\u200b\n\nTo see how those factors played out in, the researchers examined the activity of 10.1 million anonymized American Facebook users across 7 million different web links shared on the social network over a recent six-month period. Those links were classified as either \u201chard,\u201d meaning national and international news and politics, or \u201csoft,\u201d meaning sports, entertainment, travel. (Only about 13 percent of the links shared fell into the \u201chard\u201d category, which might indicate something right there about the future of the news industry and/or the country.)\n\nThe first of those factors \u2014 what friends share \u2014 works to narrow the range of ideas Facebook users on both sides of the aisle come across, with the effect greater on the left, according to the study: \u201cDespite the slightly higher volume of conservatively aligned articles shared, liberals tend to be connected to fewer friends who share information from the other side, compared to their conservative counterparts: 24 percent of the hard content shared by liberals\u2019 friends are cross-cutting, compared to 35 percent for conservatives.\u201d On top of that, the most frequently shared links were clearly aligned with liberal or conservative thinking, meaning less partisan stories didn\u2019t get spread around as much.\n\nFacebook\u2019s algorithmic News Feed \u2014 which aims to show people content that they will like \u2014 also plays some part in reinforcing those ideological barriers, as the study finds that conservatives see about 5 percent less content from the other side of the spectrum than what their friends share while liberals see about 8 percent less purely as a result of how stories are ranked and filtered.\n\nStill, the researchers conclude that users themselves play a greater role in creating their own news echo chambers: Individual choices about what to click on reduced exposure to ideas from the other side of the political spectrum by 17 percent for conservatives and 6 percent for liberals.\n\nIn other words, despite the proliferation of news and opinion sources \u2014 and despite the fact that Facebook friendships can and do cut across ideological lines more than 20 percent of the time, on average \u2014 people tended to close themselves off by not clicking on stories that clashed with their own thinking.\n\nIn an analysis accompanying the Facebook study, David Lazer, a professor of political science and computer science at Northeastern University, notes that changes to Facebook\u2019s algorithmic curation \u2014 and to Facebook users\u2019 behavior \u2014 could turn a small effect today into a large one tomorrow. \u201cIronically,\u201d he writes, \u201cthese findings suggest that if Facebook incorporated ideology into the features that the algorithms pay attention to, it would improve engagement with content by removing dissonant ideological content.\u201d\n\nThat and other political implications of Facebook\u2019s social algorithms bear monitoring, Lazer writes, but the study makes clear that if Americans are going to break out of their echo chambers, they\u2019ll have to change their own behavior. Until then, we have plenty of pictures of cute kittens and precocious babies to share.\n\nTop Reads from The Fiscal Times:", "article_metadata": {"og": {"site_name": "The Fiscal Times", "description": "Fox News and other television and online outlets long ago proved the appeal of confirm", "title": "Is Facebook Ruining Democracy?", "url": "http://www.thefiscaltimes.com/2015/05/07/Facebook-Ruining-Democracy", "image": "http://cdn.thefiscaltimes.com/sites/default/files/reuters/wpid-2012-05-31T155310Z_1_CBRE84U185K00_RTROPTP_2_FACEBOOK.jpg", "type": "article"}, "twitter": {"url": "http://www.thefiscaltimes.com/2015/05/07/Facebook-Ruining-Democracy", "image": "http://cdn.thefiscaltimes.com/sites/default/files/reuters/wpid-2012-05-31T155310Z_1_CBRE84U185K00_RTROPTP_2_FACEBOOK.jpg", "creator": "@yuvalrosenberg", "card": "summary", "title": "The Fiscal Times"}, "viewport": "initial-scale=1, maximum-scale=1", "description": "Fox News and other television and online outlets long ago proved the appeal of confirm", "generator": "Drupal 7 (http://drupal.org)"}, "_id": "\"57477af36914bd0286fcb84e\"", "article_summary": "In an analysis accompanying the Facebook study, David Lazer, a professor of political science and computer science at Northeastern University, notes that changes to Facebook\u2019s algorithmic curation \u2014 and to Facebook users\u2019 behavior \u2014 could turn a small effect today into a large one tomorrow.\nResearchers at Facebook and the University of Michigan looked at how three different factors affect the ideological diversity of the stories users see and click on in their Facebook feeds.\n(Only about 13 percent of the links shared fell into the \u201chard\u201d category, which might indicate something right there about the future of the news industry and/or the country.)\n\u201cThe media that individuals consume on Facebook depends not only on what their friends share, but also on how the News Feed ranking algorithm sorts these articles, and what individuals choose to read,\u201d their study explains.\nThose links were classified as either \u201chard,\u201d meaning national and international news and politics, or \u201csoft,\u201d meaning sports, entertainment, travel."}