{"article_title": "Analytics, BI, AI and Bad Information", "article_keywords": ["information", "likely", "analytics", "ai", "intelligence", "problems", "bi", "reports", "wasnt", "bad", "systems", "questions", "problem"], "article_url": "http://www.itbusinessedge.com/blogs/unfiltered-opinion/analytics-bi-ai-and-bad-information.html", "article_text": "Six Big Business Intelligence Mistakes\n\nI had an interesting chat with Arijit Sengupta, CEO of Beyondcore, this week. Beyondcore is one of the emerging companies that is starting to move the analytics market into the next phase of intelligent systems or artificial intelligence (AI). Sengupta agreed with my earlier piece on IBM\u2019s Watson Analytics, a competing platform, and the two big problems I identified as we transition to AI models for analytics and business intelligence. First, these systems will take a substantial amount of time to train. Second, executives using the systems need to know the right questions to ask. He added a third problem: Most BI systems have bias built in at the front end. This problem is translating into analytics products that don\u2019t work and AI systems that can\u2019t be right. Unfortunately, there is a good chance most of the intelligence systems in the world suffer from this design flaw.\n\nMy Own Experience with Analysis and Bad Information\n\nThis conversation really hit home because I recalled a troubling experience at IBM early in my career. An executive come to me with a problem: Some of our biggest banking customers had Severity One problems that had been open for nearly a year. Severity One problems were measured in minutes, and the management reports indicated that they were normally being solved in minutes, not months or years. When we did the causality analysis, we found that a policy allowed the call center to dispute a trouble report and that until the dispute was resolved, it ended up in a disputed bucket that wasn\u2019t reported. Since staff were measured on the time these problems remained open, they wouldn\u2019t remove them from the disputed classification until a solution was found. Management was unaware of the problems because the reports that management received didn\u2019t capture this behavior; it was weeded out early.\n\nI also did an in-depth review of why IBM had to fire its CEO in the early 90s. In short, it was largely because those surrounding the CEO would scrub the information he received. He never saw the problems that resulted in his firing until they were so obvious that the board became aware of them -- and were forced to fire the CEO.\n\nIn both cases, this wasn\u2019t a management failing. It was a system failure. The failures not only created erroneous reports, they resulted in bad decisions that were career threatening, not only to the employees who corrupted the process, but the executives who used the flawed reports to make decisions.\n\nI\u2019ve observed the firing of a lot of executives and CEOs over the years, and it has generally come down to one thing. They made the wrong decisions based on bad information. Often, the systems and people that actually caused the termination survive to plague the next administration, which speaks to why many turnaround efforts fail.\n\nAnalyzing Bad Information in the Affordable Care Act\n\nApparently, Beyondcore was brought in at one point as part of an audit to figure out why the Affordable Care Act wasn\u2019t performing better financially. Looking at the data, the company determined that there had been a flaw in the data capture. One of the key assumptions in the program planning was that young members would generate far more revenue than they would consume in insurance services, funding older members who would contribute far less than they would consume. For 83 percent of the young population, the assumption was true. Unfortunately, for 17 percent, it wasn\u2019t. That 17 percent consumed, on average, $7,000 in mental health charges annually. Since the contribution for the young members was set at $1,000 per year, the math no longer worked for this group. Worse, in theory, those with these expenses had a greater incentive to sign up and contribute to the program than those who did not, potentially creating an even wider gap between services and revenues. In this instance, the root of the problem was likely twofold. People wanting the bill to pass didn\u2019t want to find problems like this and not only didn\u2019t look for them, they likely objected if anyone else pointed them out.\n\nAnalyzing Bad Information Against the Affordable Care Act\n\nThe Republican Party also has a set of beliefs about the Affordable Care Act, that largely have proved to be untrue. The points presented in order to block the Act are missing, for the most part, actual problems that could have better supported their position. In short, they prevented themselves from seeing actual problems, even though they were looking for them, because they didn\u2019t base their positions on facts, but beliefs. And most of their beliefs had no more data behind them than the Democrats supporting the program did. They concluded that the program was bad before doing the analysis.\n\nDeath by Bias\n\nThis kind of series of errors is likely why companies with BI systems in place don\u2019t seem to do that much better than those without, even though these systems should provide a substantial advantage. It is because the information going into the systems has been altered before the analysis. When that is done, the analysis can\u2019t be accurate. Instead of assuring success, it more likely will assure failure. This isn\u2019t a technical problem; it is a process problem.\n\nWrapping Up: Knowing Which Questions to Ask and the Future of AI\n\nOne of the big problems with intelligence systems is that the user may not know which questions to ask. This is where systems like Beyondcore are increasingly focused. Training executives, who have substantial distractions and like to see information that agrees with their world view, to ask the critical questions likely won\u2019t work. The system has to point to anomalies in the data and recommend actions based on them, or the decision maker is likely to ignore the information they don\u2019t like and fail as a result. In that case, the system whether it is BI or AI, will have failed because the human element, rather than being an asset, has become the biggest liability.\n\nRob Enderle is President and Principal Analyst of the Enderle Group, a forward-looking emerging technology advisory firm. With over 30 years\u2019 experience in emerging technologies, he has provided regional and global companies with guidance in how to better target customer needs; create new business opportunities; anticipate technology changes; select vendors and products; and present their products in the best possible light. Rob covers the technology industry broadly. Before founding the Enderle Group, Rob was the Senior Research Fellow for Forrester Research and the Giga Information Group, and held senior positions at IBM and ROLM. Follow Rob on Twitter @enderle, on Facebook and on Google+", "article_metadata": {"description": "Most BI systems have bias built in at the front end. This is translating into analytics products that don\u2019t work and AI systems that can\u2019t be right.", "inject_params": "WT.qs_dlk=V0YzCwrIZ7kAAAExLZEAAAAH&", "robots": "index,follow", "articleKey": 175926710, "WT.qs_shmv": "hv20150423-statler.sf.quinstreet.net", "WT.qs_dlk": "V0YzCwrIZ7kAAAExLZEAAAAH", "qs.quad.keywords": "{keywords:\"107300|96040|95920,95880|935613|95850\",nodes:\"95880,95920,107300\"}", "keywords": "business intelligence, BI, AI, artificial intelligence, analytics, beyondcore, data analytics", "DCSext.tax": "product applications business intelligence analytics reporting software,product applications,product applications business intelligence analytics big data analytics,product it management practices,audience purchase stage awareness", "DCSext.qse_b2b_tax": "product applications business intelligence analytics reporting software,product applications,product applications business intelligence analytics big data analytics,product it management practices,audience purchase stage awareness"}, "_id": "\"57477af36914bd0286fd008d\"", "article_summary": "Analyzing Bad Information Against the Affordable Care ActThe Republican Party also has a set of beliefs about the Affordable Care Act, that largely have proved to be untrue.\nThey made the wrong decisions based on bad information.\nUnfortunately, there is a good chance most of the intelligence systems in the world suffer from this design flaw.\nThis problem is translating into analytics products that don\u2019t work and AI systems that can\u2019t be right.\nTraining executives, who have substantial distractions and like to see information that agrees with their world view, to ask the critical questions likely won\u2019t work."}