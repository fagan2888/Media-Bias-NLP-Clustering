Some medical conditions require and receive immediate care. People who are having heart attacks or who have suffered life-threatening injuries are typically seen by doctors as soon as they arrive at the hospital. But in less urgent cases, patients arriving at the emergency room can wait for hours before seeing a doctor, receiving pain medication, having tests, or being admitted to the hospital. And unless you had the foresight to call ahead, there is little way to know how long your visit will take.

Today we're launching an interactive news application called ER Wait Watcher, which gives you a little more information to work with. The app, which uses nationwide data recently released by the federal government, shows you how long it takes, on average, to see a doctor or other licensed professional at hospitals near you, plus the time it takes to drive there. In many cases, the hospital closest to you may not be your best bet, because of long waiting times. Traveling farther may get you in front of a doctor sooner.

If you think you're having a heart attack, or if you've suffered a serious injury, you should not use ER Wait Watcher. Please call 911. The ambulance will take you to the closest hospital, and won't be as affected by traffic because it can speed and run red lights.

The app uses data from the Centers for Medicare and Medicaid Services on measures of "Timely and Effective Care." These measures are based on a year's worth of data that CMS updates quarterly (the last update was Dec. 12, 2013). It includes averages for how long patients tend to wait before seeing a doctor, how long they spend in the emergency department before being sent home or admitted to the hospital, and how many leave without being seen at all. All data is reported voluntarily by hospitals, which have a financial incentive to participate.

ER Wait Watcher also estimates in real time how long it would take to drive to nearby hospitals based on current traffic conditions. It fetches this data directly from Google, so travel times will change throughout the day.

While minutes matter when you're having a medical emergency, longer wait times are not always an indicator of worse care. For example, emergency rooms that see more patients with behavioral health problems like alcohol abuse may have much longer wait times; it may take hours for a patient to sober up enough to be safely discharged.

And time is not the only important factor, of course, so the app also includes patient satisfaction scores and other hospital quality measures to help you make an informed decision about which emergency room to go to.

The federal data includes what researchers say are important quality metrics for the nation's emergency departments. According to Dr. Jeremiah Schuur, an emergency physician at Brigham and Women's Hospital in Boston, the most useful measure from a patient's perspective is waiting time — the time from when a patient walks in the door to when he sees a doctor. Other emergency room measures, such as total length of stay at the hospital, may vary more depending on condition (a head fracture may take longer than a dislocated elbow) or on other patients (some hospitals treat sicker patients). But whether or not a patient is seen quickly is a measure that can be compared across hospitals, says Schuur.

CMS's move to standardize how to measure the quality of emergency care is especially needed now. In the last two decades an increase in ER patients, many of them older and sicker, has led to overcrowding. Nationwide, ambulances are now turned away once a minute from overcrowded ERs and hospitals have difficulties in finding specialists to take emergency calls. Some patients leave in frustration without being seen at all, while others can wait many hours for a hospital bed to become available. This confluence of problems led the Institute of Medicine to warn that emergency rooms in the United States are "at a breaking point."

Overcrowding is not just an annoyance, and doesn't just affect the people who come in complaining of a headache. A study of almost a million admissions to 187 California hospitals found that patients who were admitted after going through a very crowded emergency room were at 5 percent greater odds of dying than those admitted after passing through a less-crowded emergency room.

To tackle the problem, some experts advocate more measurement. Publicly releasing quality metrics can drive meaningful improvements in emergency care, according to a recent article in Health Affairs, a health policy journal. And the strategy has had some success in the past.

In 2004 hospitals began to publicly report a quality measure called "door-to-balloon time." It refers to the time between a heart attack patient's arrival at the emergency room and the moment of surgical intervention (which can sometimes involve inflating a thin balloon inside a heart artery). CMS used door-to-balloon time to determine a portion of a hospital's Medicare payment. Since then, emergency departments have focused a great deal of effort and money on identifying patients with heart attacks by screening them at triage. This has led to improvements in care for heart attack patients.

But not all measurements have had the same success. In 2005, England tried implementing another measure — a "four-hour rule" for the length of time a patient could stay in the emergency room before being sent home or admitted to the hospital. The country's health service mandated that hospitals reach this four-hour time limit for 98 percent of their patients. While nearly all hospitals met the goal, many also found ways to game the system, for example transferring patients to another doctor right before the clock ran out. Since 2010, England has relaxed this measure and introduced new ones such as time to triage and percentage of patients who left without being seen.

Some U.S. emergency departments advertise their own quality care metrics, for example by posting waiting times on their websites, on billboards or on smartphone apps. For people with conditions that are not life-threatening, this information allows them to postpone their trip or avoid a busy hospital altogether. Theoretically this could help distribute patients more effectively and avoid pockets of crowding, improve patient satisfaction and serve as an incentive for hospitals to speed up their services.

But that information may not be reliable, or useful for comparing hospitals. On their own websites, hospitals are free to advertise any definition of "waiting time" they choose. While one hospital could choose to count the time from when a patient arrives to when she is evaluated by a doctor, another could decide it's when a patient is seen by a triage nurse, or receives a welcome from the hospital greeter.

In order to solve these discrepancies, CMS established standard definitions and a common metric with which to accurately compare different hospitals. The agency defines its own "waiting time" measure as the time from when a patient walks in the door to when he is evaluated by a licensed provider (a doctor, physician assistant or nurse practitioner). CMS says its specifications state clearly who qualifies, to avoid confusion.

A caveat: Hospitals may record these times inaccurately. In most cases someone must manually write down the time a patient was seen, so the times are not always precise. To combat this, some emergency rooms outfit doctors and nurses with electronic badges that wirelessly record exact times.

According to CMS, hospitals have 30 days to review their data before submitting it to the government. The agency places most of the responsibility on hospitals for making sure their data is correct before doing so.

Instead of emphasizing timeliness, future measures could look at effectiveness of care or how well emergency departments utilize resources, according to Dr. Schuur. While the newly released data is extremely important to enable individual hospitals to improve their operations, he said, "consumers should be aware that there is much more to the quality of an emergency room than how quickly they see you."