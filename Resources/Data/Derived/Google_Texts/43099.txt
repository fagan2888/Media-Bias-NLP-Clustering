How to Make Your Speeches Better, Automatically

by Nathan Collins

(Photo: hxdbzxy/Shutterstock)

Speechwriters spend a lot of time tweaking politicians’ statements in an effort to sway voters. Many even go so far as to use focus groups to figure out which words and phrases are most effective. It’s grueling work, to be sure. There could be a fix on the horizon: political science may have found a way to streamline the process, thanks to a sophisticated computer algorithm and a mix of online polls.

Traditionally, speechwriters have tested out ideas on either colleagues or in-person focus groups, who would listen to a part of a speech and report on how much they liked it, and whether it improved their opinions of the politician giving the address.

Speeches often cover many ideas and topics, and are interpreted by members of the audience through their own, equally complex lenses.

It is, according to Northeastern University political scientist Nicholas Beauchamp, pretty much trial and error. As if that’s not tricky enough, speeches often cover many ideas and topics, and are interpreted by members of the audience through their own, equally complex lenses.

What to do? Beauchamp chose to merge conventional focus groups with methods drawn from a relatively new field in political science, called text-as-data. Beauchamp started by gathering statements from obamacarefacts.com, and measuring how much each one reflected topics including costs, government, or employer mandates. A computer algorithm then generated trios of statements, which it fed to real people via crowdsourcing website Mechanical Turk. Each individual read a trio and responded by rating Obamacare on a nine-point approval scale.

Here’s the key step: Once the algorithm had presented one set of statements and collected each person’s Obamacare approval rating, it tried another set of statements and got another set of approval ratings. If the new ratings were higher, then in a sense the algorithm was moving in the right direction — that is, moving toward a blend of topics that would garner higher approval ratings, and it should keep going in that direction. If not, the algorithm tried a set of statements that moved in a different direction.

After 22 iterations of that process, Beauchamp’s algorithm managed to find a mix of topics, represented in a particular trio of statements, that improved Obamacare approval ratings 30 percent, from neutral (five points) to 6.5. Topics related to laws, rights, and government tended to turn people off Obamacare, while sentences related to employer mandates or pre-existing conditions boosted approval.

The method could be used in a variety of settings, “whether it’s political ads, whether it’s political speechwriting … it could be used in any marketing,” Beauchamp says. The tool itself is neutral, he says, though it might help shed light on another of his interests: whether persuasion, “usually considered to be a devious hobby,” can be used for good as well as something less positive.

Quick Studies is an award-winning series that sheds light on new research and discoveries that change the way we look at the world.