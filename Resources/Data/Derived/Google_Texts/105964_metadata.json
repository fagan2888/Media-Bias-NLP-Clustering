{"article_title": "Are We Getting It Right?", "article_keywords": ["surveys", "right", "getting", "estimates", "insurance", "phone", "conducted", "survey", "coverage", "rates", "health", "response"], "article_url": "http://healthaffairs.org/blog/2015/05/12/counting-the-uninsured-are-we-getting-it-right/", "article_text": "Marc Berk\n\nMay 12, 2015\n\nA May 5 government report claims that over 16 million Americans have obtained coverage as a result of the Affordable Care Act. This estimate, as well as others that are being or will soon be circulated, are based on rapid turnaround surveys conducted by telephone or over the web.\n\nSome of these efforts have gone through rigorous peer review and are being published in leading journals, including Health Affairs. While these efforts will encourage useful debate, it is important to recognize that in the past such surveys have been shown to underestimate the number of people who lack coverage.\n\nWe will soon have estimates from sources using in-person interviews. These sources are likely to document a dramatic decrease in the number of Americans who lack health insurance. It is understandable that there is intense interest in results under the ACA, but caution is warranted in using results from the rapid turnaround surveys.\n\nThe ACA debate remains polarized; and those of us who support the law will not be helped by any research that is subsequently shown to have undercounted the uninsured and thus even moderately inflated the actual number of people who obtained coverage.\n\nThe Methodological Issue Behind The Debate\n\nSurveys of insurance coverage have been among the most difficult to conduct over the phone. Phone surveys often produce incorrect estimates that overcount the number of people who have coverage. There are two major types of errors that occur in these surveys.\n\nOne is measurement error \u2014 people may not report as accurately over the phone as they would in an in-person interview; some will report they are covered when they are not. They may have an expired policy, or a survey respondent who reports for the whole household may not realize that not all family members are covered under the policy. These errors are reduced when surveys are conducted in-person.\n\nThe second problem is nonresponse error; many people refuse to be surveyed, and those who don\u2019t respond to the survey may have different coverage than those who do.\n\nThe efforts the Government makes to collect insurance data are exhaustive, expensive, and take time to implement, but they do produce accurate estimates. Among the most widely respected national health surveys are the National Health Interview Survey conducted by the National Center for Health Statistics, and the Medical Expenditures Panel Survey conducted by the Agency for Health Care Research and Quality. These surveys are usually conducted in-person. Interviewers receive extensive training, including how to examine insurance cards and other documents a survey respondent may need to accurately report coverage.\n\nMost importantly, the surveys have high response rates \u2014 the majority of those asked to participate do so. Their downside is timeliness. Complex surveys take time to field, to process the data, and to make it available for analysis. Full data release of all variables collected over the entire field period can take more than a year.\n\nReasons For Caution\n\nThe interest in conducting timely evaluation of the ACA has generated more interest in and use of quick turnaround surveys. The Urban Institute has released a comprehensive report detailing the strengths and limitations of seven new surveys conducted in the private sector that are able to produce estimates much faster than the usual Government surveys that generally have been used to monitor insurance coverage.\n\nSome of these rely on telephone data collection, but there are also some efforts to create panels of persons who agree to regularly participate in surveys using the web. The panels are recruited randomly and those without computers are provided with free computers, as well as internet access.\n\nThere is an important but limited role for such quick turnaround efforts. They can inform us about a variety of issues relevant to health care reform. Most opinion research is conducted using quick turnaround surveys; since opinions research is very dynamic, data must be collected and then almost immediately released. In 2012 and 2014, these surveys were very useful in making election predictions. The web and phone panel surveys that have been developed allow us to conduct longitudinal studies of public opinion, knowledge of ACA provisions, and certain types of behavioral issues.\n\nHowever, producing estimates about public opinion involves different challenges than fact-based estimates such as coverage status, and there is little clear evidence to show that phone or internet surveys are effective in counting the uninsured. Response rates for both quick turnaround phone surveys and web panel surveys are proprietary but known to be between 5 and 10 percent. By contrast, for federal surveys the Office of Management and Budget (OMB) requires a detailed plan to assess bias on any survey with a target response rate of less than 80 percent.\n\nThe OMB rules might be somewhat archaic; while surveys conducted by the Census Bureau can still approach 90 percent, many government health surveys fail to hit the 80 percent level. Government sponsored general population surveys, however, will almost always have response rates exceeding 60 percent; this includes government phone surveys that have longer field periods than the fast turnaround surveys described above. The National Health Interview Survey and the Medical Expenditures Panel Survey both have high response rates and conduct most of their interviews in person.\n\nHow Phone Responses Are Different\n\nSurvey experts have long known about the difficulty of collecting information about insurance coverage over the phone. Almost 25 years ago, researchers who designed a survey for the Robert Wood Johnson Foundation concluded that \u201cany efforts to generalize from persons in telephone households about the likelihood of risk of being without insurance\u2026 are extremely treacherous.\u201d\n\nA few years later I was the lead investigator on another access survey sponsored by RWJF. Most respondents were interviewed over the phone, but based on the previous effort we conducted in-person interviews with respondents who didn\u2019t have phones. This procedure eliminated the problem of households without phones, but our approach only corrected for about half of the undercount of the uninsured.\n\nIt turns out that it\u2019s not just whether or not you live in a household without a phone \u2014 telephone respondents answer insurance questions differently. In 2006, staff at the National Center for Health Statistics conducted an analysis and concluded that for most variables use of phone interviews did not increase bias. But they were clear, \u201cOne important exception was lack of health insurance.\u201d\n\nIt should be noted that while these evaluations were of telephone surveys, they were surveys that had achieved response rates of over 70 percent. Despite these high response rates significant undercounts of the uninsured occurred. If these undercounts were found in telephone surveys with response rates of 70 percent, how likely is it that phone and web surveys with single digit response rates are getting it right?\n\nThe Limitations Of Weighting\n\nWhen organizations that conduct low response rate surveys describe their methodology, they invariably note that their data is \u201cweighted\u201d to adjust for non-response bias. Thus, if women or Hispanics or the poor have high rates of nonresponse, the answers from persons in those groups who choose to respond are given greater consideration so that all key groups are proportionally represented. The problem is that developing corrective weights for any subgroup only works if members of these groups who respond have rates of coverage similar to those who don\u2019t.\n\nWeighting is an important and often necessary step in making survey estimates, but there are limitations to what it can accomplish. Weighting doesn\u2019t help if the factors influencing survey response are also associated with the probability of coverage. Consider the following hypotheses:\n\nPeople who don\u2019t like spending a lot of time on the phone are less likely to be in a phone survey and were also less likely to have bought insurance over the phone from an Exchange.\n\nPeople who don\u2019t like spending time on the internet don\u2019t do web surveys and don\u2019t purchase insurance through the web.\n\nPeople who don\u2019t see a need for insurance don\u2019t follow the issue carefully. It isn\u2019t a salient issue for them so they don\u2019t buy insurance and are also less likely to be interested in a survey about insurance.\n\nIf any one of these were true, it would likely bias survey results.\n\nMany survey methodologists have argued that too much attention is being placed on response rates and I generally agree. But there are limits. Those of us who believe a 50 percent response rate yields similar data as a survey with a 70 percent rate don\u2019t believe that any response rate at all is acceptable.\n\nLooking Forward\n\nSo how will this issue play out? As noted, the Federal Government\u2019s standards for surveys are high and government researchers usually stick to surveys that can withstand extensive scrutiny. In 2015, however, the Department of Health and Human Services (HHS), responding to tremendous interest, has chosen to make estimates based on private-sector quick turnaround surveys.\n\nAs mentioned earlier, on May 5, the HHS Assistant Secretary for Planning and Evaluation reported that 16.4 million Americans had gained coverage. The Government estimates were derived from ASPE\u2019s analysis of Gallup Healthways Wellbeing Survey, conducted by phone. To add to the confusion, as the HHS report was released, Gallup announced that the government estimate was inconsistent with Gallup\u2019s analysis of the data; Gallup estimated that less than 10 million people obtained coverage.\n\nThe wait for insurance data from government studies featuring higher response rates and in-person interviews will be a short one. An evaluation of improvements in coverage among young adults using 2014 data from the National Health Insurance Survey has already been published. Hopefully, the results from these Government surveys will not contradict the findings that HHS has already released, but I anticipate we will find that those without coverage were undercounted.\n\nIf it turns out that the number of uninsured was not accurately measured, future coverage estimates should return to the methods that have served us well. We might also consider allocating additional resources to strengthen and expedite the release of critical Government surveys that will help us better evaluate the ACA.", "article_metadata": {"og": {"url": "http://healthaffairs.org/blog/2015/05/12/counting-the-uninsured-are-we-getting-it-right/", "site_name": "Health Affairs", "image": "http://healthaffairs.org/blog/wp-content/uploads/Blog_Berk.jpg", "type": "article", "title": "Counting The Uninsured: Are We Getting It Right?"}, "description": "Counting The Uninsured: Are We Getting It Right? | At the intersection of health, health care, and policy.", "viewport": "width=device-width, initial-scale=1"}, "_id": "\"57477af46914bd0286fe1790\"", "article_summary": "If these undercounts were found in telephone surveys with response rates of 70 percent, how likely is it that phone and web surveys with single digit response rates are getting it right?\nThese sources are likely to document a dramatic decrease in the number of Americans who lack health insurance.\nWeighting is an important and often necessary step in making survey estimates, but there are limitations to what it can accomplish.\nAn evaluation of improvements in coverage among young adults using 2014 data from the National Health Insurance Survey has already been published.\nThe Methodological Issue Behind The DebateSurveys of insurance coverage have been among the most difficult to conduct over the phone."}