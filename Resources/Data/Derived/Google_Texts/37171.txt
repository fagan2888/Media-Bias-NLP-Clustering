This is what most people look like when they get a polling call. (Robert A. Reeder/Washington Post)

The New Yorker's Jill Lepore has a deep dive into the world of polling in the latest edition of the magazine. The piece asks a very pointed question: Is polling a good thing for us as a society? Her argument goes like this: There are ever more polls to tell us what we think about, well, everything, even as the polling industry faces challenges from all sides due to low response rates and a move away from landlines -- among other things. As an avid consumer and student of political polling, I wondered what professional political survey researchers thought about Lepore's conclusions about their industry. I reached out to Glen Bolger, a partner in the Republican firm Public Opinion Strategies, and Fred Yang, a partner in the Democratic firm Garin-Hart-Yang, to answer a few questions about her piece for me. They obliged. Our conversation, conducted via e-mail and edited only for clarity and grammar, is below.

FIX: In her piece, Lepore writes: "Pollsters rose to prominence by claiming that measuring public opinion is good for democracy. But what if it’s bad?” How would you respond to her question?

YANG: Clearly there are challenges to accurately measuring public opinion (see answer to next question). But since when it is a bad thing to get as much information as possible about how the public feels on important (and not-so-important-that-may-become-important) issues of the day? I would argue that having a sense of what the public thinks, which includes but is not limited to polling, is essential to giving the average person a voice and not just those with access or the loudest voice.

BOLGER: Polling can be misused, but it is not bad for democracy. And, every two years, we have the ultimate test of polling – called elections. Do elected officials over-rely on polling? I don’t think so. I can count on one hand the number of times in 30 years of doing this that I’ve been called before a big vote and asked about public opinion by a Member of Congress. And even then it was not, “how should I vote,” but more to get a sense of the nuances in the polling.

The author of the article never makes the case that polling is bad for democracy. She makes the case that polling correctly is more difficult than it used to be (which is clearly true), but never makes a case for why survey research is bad for [us].

Polls don’t drive voters, positions, or election outcomes, or else Jack Conway would be busy preparing to be the governor of Kentucky right now. When all the public polls showed Kay Hagan ahead of Thom Tillis in the North Carolina Senate race in 2014 and the pundits all predicted her re-election, my polls showing Thom Tillis was tied and poised to win were largely ignored by the press. But Tillis won. And those examples are just the tip of the iceberg.

At the same time, politicians do not always listen to the polls. In fact, there are times they reject them. Barack Obama, Nancy Pelosi, and Harry Reid would not have passed the Affordable Care Act if they were paying attention to the polls. (Of course, the American public got their revenge in the 2010 and 2014 elections.)

With polling, to quote one of Chris Cillizza’s favorite phrases, “It is what it is.”

FIX: One of the central critiques of her piece is that response rates for live-caller surveys is now in the single digits, making it harder and harder to get an accurate representative sample of the public mood? How do you guys deal with the decline in response rates? And how representative can any sample be in an era in which lots of people don’t have landlines and even more don’t want to stay on the phone and be polled?

BOLGER: There is no question declining response rates make polling a representative sample much more difficult than it used to be. We, like most of the top pollsters, are experimenting with different methodologies, including mobile. So far, any Internet/mobile polling has challenges to getting a representative sample. Most of surveys now include 40 percent of the interviews being done with cell phone respondents, and as of the 2015 elections, that blended methodology of cells and landlines is still best for political polling. The costs of doing political polling are much higher, so there will likely be fewer polls done in campaigns.

YANG: Selecting and interviewing the correct universe has been a challenge from the dawn of polling; the industry, in its transition from in-person to telephone to the new frontier of the Internet (and beyond), has been able to successfully adapt to new techniques and technologies, and oftentimes improve its accuracy, and I think this will be the case for the polling industry. For example, the decline in response rates is a major challenge, but we are able to mitigate some of it (not all) with the fact that the samples themselves are becoming more accurate and we are better able to target our interviews to “hard core” voters whose vote history (along with dozens of other factors) is embedded in the sample.

FIX: There’s lots of discussion in the article about Internet polling. And even big traditional mainstream media companies like NBC are starting to conduct surveys with Internet firms like Survey Monkey. What do you make of it?

YANG: I think the jury is still out on Internet polling. Every year we are doing more surveys over the Internet, but at least in the political world, it is still a relative new technology that we are experimenting with. The biggest challenge with Internet polling frankly is the “sample”—it is difficult (although less so as time goes by) to have enough Internet panelists for races the size of congressional districts. I think that will be one of the barriers to more full-scale use of the Internet as a reliable opinion research vehicle.

BOLGER: It possibly is. It’s too soon to say what the future of polling will look like exactly, but it will probably include a blend of cell phone, mobile, and Internet polling. The question is, when will that be? I don’t know the answer to that.

FIX: Explain, in your mind, the key differences between polling and data science/modeling. What do you think the advantages of polling are compared to modeling?

BOLGER: First, let me lay out the difference between media polling and campaign polling. Media polling seeks to give their readers/viewers/listeners a snapshot of the political race at the time, often using it to predict the outcome of the race. Pollsters for campaigns first and foremost use polling to help a campaign use the rest of its resources to help win the campaign by understanding two main points – who are the demographic targets needed to win, and what is the message that resonates best with those voters. The electorate is not static and can be moved by a strong candidate running a good campaign. And, that good campaign often uses contrasts to move some voters off their opponent. Campaign pollsters often will conduct much lengthier polls of 15 to 20 minutes because we are testing messages. And, obviously, not everything we test works, so not everything in a poll will show up in a campaign.

What good data modeling does is take what the polling has learned across a sample of the electorate and apply it to individuals in an effort to classify each voter as base (and thus turnout), swing (and thus persuadable), and anti (and thus ignore). Good data science/modeling takes input from a variety of sources (polling, ID contacts, commercial and political lists) and uses it to help campaigns make decisions toward specific voters (even if in groups).

YANG: Polling and modeling can and often do work hand-in-glove. I view them as complementary. I think a key benefit of traditional polling is the ability to test messages and dynamics in a fairly rigorous way. Polling I believe helps determine WHAT to say, while modeling can be useful in WHO to say it to.

FIX: Finish this sentence: The future of polling is ______________. Now, explain why.

YANG: The future of polling is no different than its past -- good pollsters will adapt to new technologies while also remembering the best poll is the one that lets the people speak.

That’s long answer to a short question! None of my polling colleagues -- Republican or Democrat -- will dispute that our industry faces unique and sometimes vexing challenges. But all of us have a vested interest in “getting the numbers right,” and I don’t know why polling will be any different than other industries and fields that have met similar challenges unique to the 2000s and still thrive. We clearly need to deal with lower response rates, but I know everyday myself and my colleagues are thinking about and often-times experimenting with new methodologies to improve response rates. I think polls, when done right, are incredibly useful tools, and to basically throw the polls and the pollsters out along with the bathwater I think sells our industry short, and in the end, I think would be a disservice to understanding the public and trying to be more responsive to their needs. The challenge to polling is not that this field is about to disappear, but that we will not provide enough scrutiny of the work both in questionnaire design and sampling methodology and execution to know the difference between really solidly done surveys and those that are of questionable value.

BOLGER: Murky. Measuring public opinion will always be something that is done. There is too much interest for it to simply disappear. The question is how will it be done in ten years, twenty years? Polling in the 1970s, 1980s, 1990s, and 2000s was relatively stable and similar across those four decades. No one can predict the exact methodology for the future. If I could predict the future, I’d be in Vegas betting on the NFL – and against the Cubs winning the World Series.