{"article_title": "Why the Military Wants to Restore Your Online Privacy", "article_keywords": ["wants", "restore", "protect", "sharing", "big", "information", "darpa", "privacy", "research", "program", "systems", "online", "military", "data"], "article_url": "http://www.thefiscaltimes.com/2015/03/14/Why-Military-Wants-Restore-Your-Online-Privacy", "article_text": "The average, technologically connected American worker produces some 5,000 megabytes of digital data a day, enough to fill nine CD-ROMs. Only a small fraction of it is stored permanently or is clearly related to a specific identity, but the sheer volume of digital exhaust that is daily life has turned privacy into an endangered entity \u2013 and a growing national security concern.\n\nOn Wednesday, the military\u2019s Defense Advanced Projects Research Agency, or DARPA, put out an agency announcement on a program that seeks to restore some semblance of privacy to the online world.\n\nRelated: White House Releases Draft Bill to Protect Consumer Privacy\n\nThe so-called Brandeis program, named after the late U.S.Supreme Court associate justice and privacy advocate Louis Brandeis, seeks to build \u201cinformation systems that can ensure private data can only be used for its intended purpose and no other.\u201d\n\nPrivacy deprivation may be a fact of modern, inter-connected life, but if passwords, files, and personal location data can\u2019t be protected, then neither can vital pieces of information. That vulnerability can contribute to industrial theft and sabotage and worse, and the recent Sony hack and CENTCOM Twitter snafu foreshadowed this naked future. It\u2019s the military\u2019s job to protect the country from national security threats.\n\nQuestion is: In the wake of the Edward Snowden scandal and what it revealed about NSA data collection practices and capabilities, how much does anyone trust the military to, essentially, build them a privacy machine?\n\nThe specific type of data that the DARPA program seeks to protect is your transactional data or data that you knowingly stream to a site or party. But it comes with a crucial caveat \u2013 the Brandeis program addresses data \u201cthat is knowingly provided to a third party, as opposed to data collected as a byproduct of interacting with the network or a system,\u201d according to the DARPA announcement.\n\nRelated: Fighting Cyber Crime Doesn't Have to Cost a Fortune\n\nThat caveat is important for two reasons: First, the goal is not just the protection of privacy but also the protection of privacy while users are engaged in the act of sharing data.\n\nSecond, by focusing on information that citizens knowingly give to third parties rather than inadvertently provide as a result of merely interacting with machines the DARPA program rules out building any future information system that might, somehow, get in the way of the military or law enforcement collecting signals intelligence as part of investigations (to the continued objection of privacy advocates).\n\nWhy is protecting data sharing important? On this count, theDARPA announcement is so strident on the social value ofyottabytes of user-generated data that the casual reader might think the notice came from the Google press office.\n\nData sharing will create \u201cpersonal medicine (leveraging cross-linked genotype/phenotype data), effective smart cities (where buildings, energy use, and traffic controls are all optimized minute by minute), detailed global data (where every car is gathering data on the environment, weather, emergency situations, etc.), and fine grained internet awareness (where every company and device shares network and cyber-attack data).\u201d\n\nRelated: Does Your State Protect You from Prying Employers?\n\nWithout strong privacy controls, none of those futuristic visions can be realized. But protecting the privacy of people who are voluntarily sharing data is no straight-forward undertaking. The same correlational analysis that can reveal a relationship between a certain protein construction and cancer can reveal the individual that volunteered that genomic information.\n\nA person\u2019s electricity-usage patterns are distinct, based on an individual\u2019s schedule, devices, habits, etc. All of that speaks to identity. For that reason, the idea of rendering data fully and permanently anonymous is a dubious one among much of the privacy community.\n\nThe DARPA researchers acknowledge that obstacle by pointing to the work of Carnegie Melon University\u2019s Latanya Sweeney, who has shown that gender and zip code are enough to identify 87 percent of individuals by name.\n\nBut just because data is revelatory doesn\u2019t mean that all data shared with a third party is viewable everywhere or at low cost. Ideally, the user who is sharing the data should be able to control how it\u2019s viewed, rather than that responsibility falling on the third party. The point of the project is ensuring that those telltale data bits don\u2019t wind up in the wrong places.\n\nRelated: Why Your Smartphone Knows If You're Sick Before You Do\n\nThe program, which will go on for four years, will break participants up into three technical areas. The first area is privacy computing. It will take recent strategies and innovations in privacy protection, such as secure database querying, multiparty computation, (a subset of encryption that allows computers to share data even if they don\u2019t fully \u201ctrust\u201d one another), and remote attestation, (which allows a computer server to verify and authenticate the configuration of computer attempting to make contact), and use them to build a more holistic privacy computing framework.\n\nResearch into these methods has \u201cbeen promising, but to date these techniques suffer from significant practical limitations in flexibility, scalability and performance,\u201d DARPA writes in its announcement.\n\nThe second area will focus on human, digital interaction.\n\nThe goal here is to create systems that can essentially predict the difference between shareable data and more private data, help users understand the privacy tradeoff of different sharing decisions and give users faster and firmer control of what data they share and with whom they share it.\n\nRelated: When Big Data Becomes Big Brother\n\nThe third area looks to build experimental systems to \u201cprovide the platforms on which to test these ideas in practice\u201d \u2014 in essence, to create a privacy machine.\n\nJeremy Gillula, a staff technologist with the privacy watchdog group the Electronic Frontier Foundation, said he had no problem trusting the U.S. government to create privacy solutions, \u201cas long as the research is published and the information is shared with the greater privacy-technology community.\u201d He characterized the challenge that DARPA was undertaking in with Brandeis project as an ambitious one.\n\n\u201cThe research community has made some significant progress (differential privacy, secure multiparty computation, etc.), but all of these methods have some sort of weakness,\u201d Gillula said. \u201cWith that said, focusing on ways to scale these methods would certainly be a step in the right direction. It certainly wouldn\u2019t solve the whole privacy problem, but at the same time solving the whole privacy problem would be way too big to tackle in a single project.\u201d\n\nJulian Sanchez, a senior fellow with the libertarian-leaning Cato Institute, told Defense One he found it \u201csomewhat reassuring to see the DARPA solicitation indicates a preference for open source proposals, since that would in practice be a prerequisite for any tools that might be made available for broader public use.\u201d\n\nRelated: How Big Cities Mine Big Data to Solve Big Problems\n\nHe added that it was, \u201ccertainly valuable for DARPA to be sponsoring research into protective information sharing systems of this kind \u2014 and indeed, this should have been a priority long ago.\u201d\n\n\u201cBut citizens and courts shouldn\u2019t let themselves be gulled into blessing government data dragnets on the premise that fancy technology will somehow guarantee the data is only ever used by good people for good purposes.\u201d\n\nGillula, sounded a similar note of enthusiasm for the project, but skepticism about a total privacy solution coming out of the government \u2014 or anywhere else. \u201cThe program is focused on data willingly shared, and won\u2019t help with non-consensual third-party tracking/collection, which is a bigger concern (and more problematic) in general,\u201d he said. \u201cThe program is fine for what it\u2019s doing, but it\u2019s definitely not going to solve the greater privacy problem we face as a society.\u201d\n\nIn other words, the military\u2019s privacy machine may facilitate safer information sharing, but fixing privacy \u2014 and mistrust of government on the issue \u2014 will take more than a press of a button.\n\nThis article originally appeared in Defense One.\n\nRead more at Defense One:\n\nNavy to Increase Number of Deployed Ships\n\nPentagon Intel Analysts Use a Trick from Amazon's Book\n\nConcerns About ISIS Fighters Coming Through Southern Border", "article_metadata": {"og": {"site_name": "The Fiscal Times", "description": "The average, technologically connected American\u00a0worker produces some 5,000 megabytes o", "title": "Why the Military Wants to Restore Your Online Privacy", "url": "http://www.thefiscaltimes.com/2015/03/14/Why-Military-Wants-Restore-Your-Online-Privacy", "image": "http://cdn.thefiscaltimes.com/sites/default/files/articles/05072013_Binary_Globe_article.jpg", "type": "article"}, "twitter": {"url": "http://www.thefiscaltimes.com/2015/03/14/Why-Military-Wants-Restore-Your-Online-Privacy", "image": "http://cdn.thefiscaltimes.com/sites/default/files/articles/05072013_Binary_Globe_article.jpg", "card": "summary", "title": "The Fiscal Times"}, "viewport": "initial-scale=1, maximum-scale=1", "description": "The average, technologically connected American\u00a0worker produces some 5,000 megabytes o", "generator": "Drupal 7 (http://drupal.org)"}, "article_summary": "But protecting the privacy of people who are voluntarily sharing data is no straight-forward undertaking.\nOn Wednesday, the military\u2019s Defense Advanced Projects Research Agency, or DARPA, put out an agency announcement on a program that seeks to restore some semblance of privacy to the online world.\nWhy is protecting data sharing important?\nThe specific type of data that the DARPA program seeks to protect is your transactional data or data that you knowingly stream to a site or party.\nFor that reason, the idea of rendering data fully and permanently anonymous is a dubious one among much of the privacy community."}