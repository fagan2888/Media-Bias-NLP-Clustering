Topics: Benjamin Netanyahu, Editor's Picks, Elections 2014, Elections 2016, Frank Luntz, Matt Bevin, Mitch McConnell, Polling, Polls, News

In early October, the Gallup polling company told Politico that it would not be doing horse race polling in the current presidential primary race, and perhaps not in the general election, either. “We believe to put our time and money and brainpower into understanding the issues and priorities is where we can most have an impact,” Gallup editor-in-chief Frank Newport said.

It came as a surprise, if not a shock. In 2012 Gallup had predicted a narrow Mitt Romney win, instead of the comfortable Barack Obama victory that was actually achieved, but a serious post-mortem seemingly ensured it would continue its long tradition, dating back to 1936, of polling presidential races.

Less than a month later, on Nov. 4, the Louisville Courier-Journal and Lexington Herald-Leader announced major changes after their pollster, SurveyUSA, missed Matt Bevin’s surprisingly strong win in the Kentucky governor’s race. SUSA was hardly alone in getting the outcome wrong, however — as shown by the polling trend averages at both Huffington Post and Real Clear Politics. But it did not help that the poll also found Mitch McConnell in a much closer race for his Senate seat in 2014, and he rolled to re-election over Alison Lundergan Grimes.

“It feels like déjà vu all over again,” Harry Enten wrote at Five Thirty Eight, linking back to a Nate Silver live update as last May’s British election results showed pre-election polls had been far off. “The World May Have A Polling Problem,” Silver’s update was titled, pointing to the Scottish independence vote, the Israeli legislative election, David Cameron’s relative landslide and last year’s U.S. midterms. “It’s become harder to find an election in which the polls did all that well,” Silver wrote at the time.

As recently as August 2014, Silver had written about the problems facing pollsters, primarily driven by falling response rates (down from 36 percent in 1997 to 9 percent today, according to Pew Research), but still could say, “We have seen no widespread decline in the accuracy of election polls, at least not yet.” Fifteen months later, that no longer seems to be true.

Even when Silver wrote, there was Gallup’s black eye to consider, but Gallup had been an outlier. Most pollsters correctly predicted Obama’s victory, though they did under-estimate it overall. Now, the difficulties have become more widespread, as if the problems driven by falling response rates have finally reached a tipping point. In the case of Kentucky, Huffington Pollster’s weekly roundup pointed to a number of factors:

Although it’s difficult to know for sure, evidence points to the timing of the polls, the partisan composition of likely voters in the polls and the presence of an independent candidate. None of these alone explains the wide discrepancy between the polls and the result, but combined, they contributed to the miss.

It went on to add the sparsity of polling as well: “only six publicly released polls between August and Election Day.”

The proliferation of these problems points to an even broader phenomena than the falling response rate — an ongoing dissolution of political trust, coherence and order. Low-turnout elections in and of themselves reflect such a general democratic decay, while third-party candidates tend to signal systemic problem-solving failures and voter disaffection. Pollster Charles Franklin also highlighted how pollsters matched party registration, but not identification — a divergence that further underscores the process of dissolution.

Over on center stage, in the GOP presidential primary, there are a multitude of other ways in which this dissolution plays out, starting with the deep distrust of the political establishment reflected in the success of Donald Trump and Ben Carson, but also extending to the difficulties of polling — much less covering — such an enormous primary field. The RNC’s decision to let media hosts set the criteria, coupled with media decisions to use national poll aggregates and a two-tier debate format, actually empowers some of the worst fragmenting potentials that public polling can have.

But what about their potential for good?

Polling And Deliberation

Back in 2004, Gallup’s Newport published a strong defense of what Gallup then did, “The Pluses of Pre-Election Horse Race Polls.” In it, he took note of Stanford professor James Fishkin and his advocacy of deliberative polling, centered on “deliberative forums in which citizens meet and talk in a modern-day town-hall setting, based on his belief that citizens involved in such discussions might arrive at better, more informed decisions” — only to quickly dismiss him.

“But just how much does this in-person deliberating differ from the broader input from friends and neighbors provided by polls? I think not much,” Newport wrote. “Polls, in fact, are in many ways an extension of a town-hall, deliberative process. Polling simply distills the opinions of all of one’s neighbors (across the state or across the nation) in an accurate fashion — an expanded version of what the voter would find out by asking neighbors in the community where they stand on the issues of the day.”

This carelessly overlooks the very essence of the deliberative process — considering different alternatives in light of different information, and discussing the various pluses and minuses that emerge. Nothing remotely like this happens in the course of most horse race polling. But Gallup’s more recent decision to refocus on “understanding the issues and priorities” could potentially signal a move in that direction, a strategy for responding to the dissolution described above by finding another footing for the deliberative process. It’s clearly a reactive response to the most obvious symptoms — problems with predicting the horse race outcome — but if Gallup is really serious, then it needs to go much farther, and confront some deeper problems.

For one thing, issues and priorities are not at all similar for all potential voters. As I noted here in late September, Philip Converse presented evidence in 1964 that “Those with low political knowledge have little to organize their political views. They respond mostly to the ephemeral nature of the times. Then, as voters become more knowledgeable, groups become very salient, to be replaced by ideological thinking among only the most informed.”

This is not to say that public opinion is meaningless, or that public deliberation is impossible — but it is tricky. You can’t just assume that everyone responds to political questions in similar ways, which can produce coherent deliberation. They don’t. This is also a significant problem with with Fishkin’s approach. As described on his web site, the process begins with polling a random representative sample of the public, just like a normal poll, but then moves into a phase where participants are recruited for an in-person deliberative process. This process is extremely unlikely to engage the sorts of low-information citizens Converse identified as making up a substantial portion of the electorate. So how truly representative can it actually be?

The Public Interest Polling Model

Fortunately, another pollster has taken important steps in the direction of showing how deliberation can be made possible, without asking anyone to do much more than an ordinary poll would. In 1986, shortly before Fishkin began his work, Alan F. Kay launched his model of “public interest polling.” The Americans Talk Issues Foundation’s series of more than 30 polls continued over the next decade and a half.

As Kay explained the concept in 1999, “Public-interest polling is about issues — resolving community, regional, state, national and international problems. What is needed is governance that will help make the world, or our part of it, work with consensus support as easily realizable as a small town-meeting can find a consensus should it wish to.” Although it doesn’t engage participants in back-and-forth discussions with one another, it does include methods for exposing people to different arguments and discovering if they significantly change people’s views. And it doesn’t require any higher levels of political sophistication or commitment. Like the jury system, it’s open to one and all.

“Public-interest polling requires a healthy mixture of common sense and the knowledge of experts,” Kay wrote. “Questions must be fair,” they should not “lead the witness,” as lawyers would say. “Question-sets (not necessarily every question) should be balanced. The survey design team, consisting of polling and issue experts, should collectively represent a wide range of backgrounds and points of view.” And they should be willing to work through any confusions that arise, using “follow-on questions,” or split samples to pose slightly different versions for comparison, as well as serial surveys.

“Once you’ve gotten the hang of it, you can clear up all the ambiguities in one or two additional surveys,” Kay writes. “In 33 surveys, over and over again, it worked every time for my company, ATI, from 1987 to 1999.” Kay’s findings are collected in his book, Locating Consensus for Democracy – A Ten-Year U.S. Experiment.

Perhaps what’s most striking about Kay’s approach is the way he has surfaced consensus positions on a wide range of issues that most pollsters never even ask about and that few political elites ever consider. The unexpected consensus revealed should not be surprising, given the findings reported by Martin Gilens and Benjamin Page about the powerlessness of the general public. Based on a data set covering 1,779 policy issues, they reported:

Multivariate analysis indicates that economic elites and organized groups representing business interests have substantial independent impacts on U.S. government policy, while average citizens and mass-based interest groups have little or no independent influence.

In this situation, all manner of popular policies are simply ignored, unless they happen to coincide with what some powerful interest group also wants.

Kay’s results also call to mind the “Big Ideas” poll commissioned by the Progressive Change Institute in January, which I wrote about last summer. “PCI first solicited ideas online through an open submission process (more than 2,600 specific proposals were submitted) and then let people vote on them (more than a million votes were cast),” I explained. “This bottom-up process was then tested out in a national poll.”

It was a very different sort of process than Kay’s but, like his approach, it tapped into neglected sources of strong public consensus. Ideas receiving 70 percent support or more included:

Allow Government to Negotiate Drug Prices (79 percent)

Give Students the Same Low Interest Rates as Big Banks (78 percent)

Universal Pre-Kindergarten (77 percent)

Fair Trade that Protect Workers, the Environment, and Jobs (75 percent)

End Tax Loopholes for Corporations that Ship Jobs Overseas (74 percent)

End Gerrymandering (73 percent)

Let Homeowners Pay Down Mortgage With 401k (72 percent)

Debt-Free College at All Public Universities (Message A) (71 percent)

Infrastructure Jobs Program — $400 Billion / Year (71 percent)

Require NSA to Get Warrants (71 percent)

Disclose Corporate Spending on Politics/Lobbying (71 percent)

Medicare Buy-In for All (71 percent)

Close Offshore Corporate Tax Loopholes (70 percent)

Green New Deal — Millions Of Clean-Energy Jobs (70percent)

Full Employment Act (70 percent)

Expand Social Security Benefits (70 percent)

However, these ideas were all developed from a self-selected progressive base, and were not subject to winnowing through exposure to counter-arguments. What’s fascinating about Kay’s approach is that it also produced robustly popular proposals that political elites rarely considered, and the greater diversity among them has important lessons for us today, several decades after they were first uncovered.

Kay also wrote that ATI found “overwhelming evidence that the legislation and policy choices most supported by Americans are characterized by four key adjectives: stable, consistent, pragmatic and principled.” They vary only slowly over time, except in response to some major event; levels of support vary only slightly when questions are presented in different ways; solutions are pragmatic, rather than ideological, often encompassing “other dimensions” that aren’t addressed by different party proposals and “they want solutions that are good for everybody and comprehensive,” rather than simply doing what’s best for themselves alone.